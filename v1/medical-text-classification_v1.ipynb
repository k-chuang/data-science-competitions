{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR1: Medical Text Classification\n",
    "\n",
    "* Author: Kevin Chuang [@k-chuang](https://www.github.com/k-chuang)\n",
    "* Created on: September 21, 2018\n",
    "* Description: Given a medical abstract, classify condition of patient (5 classes) using K-Nearest Neighbors.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:56.648689Z",
     "start_time": "2018-09-22T05:56:55.568986Z"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Text Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Utilities\n",
    "import string\n",
    "import math\n",
    "from operator import itemgetter \n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20.0, 10.0), \"axes.labelsize\": 14})\n",
    "\n",
    "# sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:57.066083Z",
     "start_time": "2018-09-22T05:56:56.651356Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.dat', sep='\\t', header=None, names=['Label', 'Abstract'])\n",
    "test_df = pd.read_csv('test.dat', sep='\\t', header=None, names=['Abstract'])\n",
    "submission_df = pd.read_csv('format.dat', header=None, names=['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:57.078747Z",
     "start_time": "2018-09-22T05:56:57.067844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Catheterization laboratory events and hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Renal abscess in children. Three cases of rena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hyperplastic polyps seen at sigmoidoscopy are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Subclavian artery to innominate vein fistula a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Effect of local inhibition of gamma-aminobutyr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Abstract\n",
       "0      4  Catheterization laboratory events and hospital...\n",
       "1      5  Renal abscess in children. Three cases of rena...\n",
       "2      2  Hyperplastic polyps seen at sigmoidoscopy are ...\n",
       "3      5  Subclavian artery to innominate vein fistula a...\n",
       "4      4  Effect of local inhibition of gamma-aminobutyr..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:57.090125Z",
     "start_time": "2018-09-22T05:56:57.081093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excision of limbal dermoids. We reviewed the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bell's palsy. A diagnosis of exclusion. In cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retained endobronchial foreign body removal fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recurrent buccal space abscesses: a complicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intracranial fibromatosis. Fibromatoses are un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract\n",
       "0  Excision of limbal dermoids. We reviewed the c...\n",
       "1  Bell's palsy. A diagnosis of exclusion. In cas...\n",
       "2  Retained endobronchial foreign body removal fa...\n",
       "3  Recurrent buccal space abscesses: a complicati...\n",
       "4  Intracranial fibromatosis. Fibromatoses are un..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "- View a sample of the medical abstract text\n",
    "- Read through it, and I definitely had to Google some terminology\n",
    "    - Initial observations of medical abstract text\n",
    "        - There are a lot of complex medical terms (e.g. acute myocardial infarction) \n",
    "        - There seems to be a lot of n = some integer (e.g. n = 100)\n",
    "        - There seems to be a lot of percentages (e.g. 55%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:59.222145Z",
     "start_time": "2018-09-22T05:56:59.214695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null abstracts\n",
    "train_df.Abstract.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:59.389790Z",
     "start_time": "2018-09-22T05:56:59.383943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:59.558330Z",
     "start_time": "2018-09-22T05:56:59.553398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Renal abscess in children. Three cases of renal abscesses in children are described to illustrate the variable presenting features. An additional 23 pediatric cases, reported over the past ten years, were reviewed for clinical features and therapy. Fever, loin pain, and leukocytosis were common presenting features, but less than half of all abscesses were associated with either an abnormal urinalysis or a positive urine culture. The presenting features were sometimes confused with appendicitis, peritonitis, or a Wilms tumor. An organism was identified in 17 cases--Escherichia coli in 9 children and Staphylococcus aureus in 8 children. The majority of E. coli infections occurred in girls and the majority of S. aureus infections occurred in boys. Reflux was documented in 5 patients, and 2 children had a possible extrarenal source of infection. Antibiotics alone produced a cure in 10 children (38%), but 16 children (62%) required a surgical procedure. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Abstract'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:56:59.740243Z",
     "start_time": "2018-09-22T05:56:59.732847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4805\n",
       "1    3163\n",
       "4    3051\n",
       "3    1925\n",
       "2    1494\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalanced classes\n",
    "\n",
    "train_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:00.029100Z",
     "start_time": "2018-09-22T05:56:59.871642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12098ae80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Label', data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- I am going to use Bag of Words for text preprocessing\n",
    "- BOW basically breaks up the note into the individual words and counts how many times each word occurs.\n",
    "- I  remove some of the unimportant words such as 'the', 'to',\n",
    "- I will use a tokenizer and a vectorizer. \n",
    "    - The tokenizer breaks a single abstract into a list of words and a vectorizer takes a list of words and counts the words.\n",
    "- `Tokenizer`:\n",
    "    - Remove punctuation & numbers\n",
    "    - Lowercase everything\n",
    "    - Lemmatize all the text (e.g. women will become woman)\n",
    "        - Goal is reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "        - Lemmatization is the process of converting the words of a sentence to its dictionary form. \n",
    "- `Vectorizer`:\n",
    "    - `CountVectorizer`\n",
    "        - Encodes a vector with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "        - vocabulary_ is a dict/mapping of the terms to their indices in the document-term matrix, not the counts.\n",
    "    - `TfidfVectorizer`\n",
    "        - Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "        - TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "        - Term frequency-inverse document frequency is a statistic that reflects how important a word is to a specific document relative to all of the words in a collection of documents (the corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:03.911821Z",
     "start_time": "2018-09-22T05:57:03.894623Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    # Use Lemma tokenizer to tokenize the words\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lemmas = [lemma.lemmatize(word.strip()) for word in text.split()]\n",
    "    \n",
    "#     Remove one letter words\n",
    "#     lemmas = [x for x in lemmas if len(x) > 1]\n",
    "    return lemmas\n",
    "#     tokens = word_tokenize(text)\n",
    "#     tokens = [x for x in tokens if len(x) > 1]\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:07.744567Z",
     "start_time": "2018-09-22T05:57:05.745851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['renal', 'abscess', 'in', 'child', 'three', 'case', 'of', 'renal', 'abscess', 'in', 'child', 'are', 'described', 'to', 'illustrate', 'the', 'variable', 'presenting', 'feature', 'an', 'additional', 'pediatric', 'case', 'reported', 'over', 'the', 'past', 'ten', 'year', 'were', 'reviewed', 'for', 'clinical', 'feature', 'and', 'therapy', 'fever', 'loin', 'pain', 'and', 'leukocytosis', 'were', 'common', 'presenting', 'feature', 'but', 'le', 'than', 'half', 'of', 'all', 'abscess', 'were', 'associated', 'with', 'either', 'an', 'abnormal', 'urinalysis', 'or', 'a', 'positive', 'urine', 'culture', 'the', 'presenting', 'feature', 'were', 'sometimes', 'confused', 'with', 'appendicitis', 'peritonitis', 'or', 'a', 'wilms', 'tumor', 'an', 'organism', 'wa', 'identified', 'in', 'case', 'escherichia', 'coli', 'in', 'child', 'and', 'staphylococcus', 'aureus', 'in', 'child', 'the', 'majority', 'of', 'e', 'coli', 'infection', 'occurred', 'in', 'girl', 'and', 'the', 'majority', 'of', 's', 'aureus', 'infection', 'occurred', 'in', 'boy', 'reflux', 'wa', 'documented', 'in', 'patient', 'and', 'child', 'had', 'a', 'possible', 'extrarenal', 'source', 'of', 'infection', 'antibiotic', 'alone', 'produced', 'a', 'cure', 'in', 'child', 'but', 'child', 'required', 'a', 'surgical', 'procedure']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(train_df['Abstract'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.661059Z",
     "start_time": "2018-09-22T05:57:07.746545Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(tokenizer = tokenizer)\n",
    "vec.fit(train_df['Abstract'])\n",
    "X_train = vec.transform(train_df['Abstract'])\n",
    "# abstract_df = vec.fit_transform(train_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.666259Z",
     "start_time": "2018-09-22T05:57:31.663619Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.677306Z",
     "start_time": "2018-09-22T05:57:31.668679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31869"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size is around 31869 unique words\n",
    "\n",
    "len(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.710374Z",
     "start_time": "2018-09-22T05:57:31.680430Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_names = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.719747Z",
     "start_time": "2018-09-22T05:57:31.712824Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts = np.asarray(X_train.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.728764Z",
     "start_time": "2018-09-22T05:57:31.722223Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_counts_df = pd.DataFrame.from_dict({'Word':vocab_names, 'Counts':word_counts.ravel()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.741501Z",
     "start_time": "2018-09-22T05:57:31.731527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>53609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aab</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaem</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Counts\n",
       "0     a   53609\n",
       "1    aa      28\n",
       "2   aaa      27\n",
       "3   aab       7\n",
       "4  aaem       3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:31.768271Z",
     "start_time": "2018-09-22T05:57:31.744403Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28816</th>\n",
       "      <td>the</td>\n",
       "      <td>122496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20126</th>\n",
       "      <td>of</td>\n",
       "      <td>121285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>and</td>\n",
       "      <td>81967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13780</th>\n",
       "      <td>in</td>\n",
       "      <td>79415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>53609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31599</th>\n",
       "      <td>with</td>\n",
       "      <td>43935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29150</th>\n",
       "      <td>to</td>\n",
       "      <td>43083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>patient</td>\n",
       "      <td>39336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31321</th>\n",
       "      <td>wa</td>\n",
       "      <td>28458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31488</th>\n",
       "      <td>were</td>\n",
       "      <td>24358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10736</th>\n",
       "      <td>for</td>\n",
       "      <td>21779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20381</th>\n",
       "      <td>or</td>\n",
       "      <td>15422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>is</td>\n",
       "      <td>14674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>by</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28813</th>\n",
       "      <td>that</td>\n",
       "      <td>14488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28811</th>\n",
       "      <td>than</td>\n",
       "      <td>13077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>from</td>\n",
       "      <td>10611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>at</td>\n",
       "      <td>9905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>an</td>\n",
       "      <td>9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28917</th>\n",
       "      <td>this</td>\n",
       "      <td>9630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>be</td>\n",
       "      <td>9402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>had</td>\n",
       "      <td>9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>after</td>\n",
       "      <td>9296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20252</th>\n",
       "      <td>on</td>\n",
       "      <td>9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>group</td>\n",
       "      <td>8839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>cell</td>\n",
       "      <td>8682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>disease</td>\n",
       "      <td>8039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19806</th>\n",
       "      <td>not</td>\n",
       "      <td>8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20836</th>\n",
       "      <td>p</td>\n",
       "      <td>7892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>study</td>\n",
       "      <td>7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15677</th>\n",
       "      <td>le</td>\n",
       "      <td>7567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>are</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31786</th>\n",
       "      <td>year</td>\n",
       "      <td>7160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28874</th>\n",
       "      <td>these</td>\n",
       "      <td>7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>case</td>\n",
       "      <td>6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31428</th>\n",
       "      <td>we</td>\n",
       "      <td>6368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29595</th>\n",
       "      <td>treatment</td>\n",
       "      <td>6343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29828</th>\n",
       "      <td>tumor</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29884</th>\n",
       "      <td>two</td>\n",
       "      <td>5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>during</td>\n",
       "      <td>5529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>have</td>\n",
       "      <td>5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20279</th>\n",
       "      <td>one</td>\n",
       "      <td>5332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>all</td>\n",
       "      <td>5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19051</th>\n",
       "      <td>no</td>\n",
       "      <td>5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25185</th>\n",
       "      <td>result</td>\n",
       "      <td>5059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16773</th>\n",
       "      <td>may</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>but</td>\n",
       "      <td>4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>it</td>\n",
       "      <td>4675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>blood</td>\n",
       "      <td>4562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31543</th>\n",
       "      <td>who</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24290</th>\n",
       "      <td>rate</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>effect</td>\n",
       "      <td>4425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>clinical</td>\n",
       "      <td>4356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>between</td>\n",
       "      <td>4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25744</th>\n",
       "      <td>s</td>\n",
       "      <td>4197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5815</th>\n",
       "      <td>control</td>\n",
       "      <td>4180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17943</th>\n",
       "      <td>more</td>\n",
       "      <td>4115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16834</th>\n",
       "      <td>mean</td>\n",
       "      <td>3975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>associated</td>\n",
       "      <td>3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28844</th>\n",
       "      <td>therapy</td>\n",
       "      <td>3923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Counts\n",
       "28816         the  122496\n",
       "20126          of  121285\n",
       "1207          and   81967\n",
       "13780          in   79415\n",
       "0               a   53609\n",
       "31599        with   43935\n",
       "29150          to   43083\n",
       "21260     patient   39336\n",
       "31321          wa   28458\n",
       "31488        were   24358\n",
       "10736         for   21779\n",
       "20381          or   15422\n",
       "14903          is   14674\n",
       "3640           by   14561\n",
       "28813        that   14488\n",
       "28811        than   13077\n",
       "10910        from   10611\n",
       "2154           at    9905\n",
       "1123           an    9900\n",
       "28917        this    9630\n",
       "2711           be    9402\n",
       "11798         had    9393\n",
       "640         after    9296\n",
       "20252          on    9213\n",
       "11681       group    8839\n",
       "4211         cell    8682\n",
       "7755      disease    8039\n",
       "19806         not    8004\n",
       "20836           p    7892\n",
       "27678       study    7816\n",
       "15677          le    7567\n",
       "1854          are    7206\n",
       "31786        year    7160\n",
       "28874       these    7144\n",
       "4002         case    6867\n",
       "31428          we    6368\n",
       "29595   treatment    6343\n",
       "29828       tumor    5803\n",
       "29884         two    5659\n",
       "8251       during    5529\n",
       "11966        have    5398\n",
       "20279         one    5332\n",
       "855           all    5287\n",
       "19051          no    5214\n",
       "25185      result    5059\n",
       "16773         may    5037\n",
       "3608          but    4900\n",
       "15036          it    4675\n",
       "3181        blood    4562\n",
       "31543         who    4513\n",
       "24290        rate    4513\n",
       "8535       effect    4425\n",
       "4913     clinical    4356\n",
       "2863      between    4354\n",
       "25744           s    4197\n",
       "5815      control    4180\n",
       "17943        more    4115\n",
       "16834        mean    3975\n",
       "2097   associated    3940\n",
       "28844     therapy    3923"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_counts_df.sort_values(['Counts'], ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:32.347938Z",
     "start_time": "2018-09-22T05:57:31.771163Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the top 50 most frequently occurring words\n",
    "top50 = vocab_counts_df.sort_values(['Counts'], ascending=False).iloc[:50]\n",
    "\n",
    "ax = sns.barplot(\"Word\", \"Counts\", data=top50, palette=\"Blues_d\");\n",
    "ax.set_title('Top 50 Words')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "- Stop words are words we do not want to use as features, and shall remove from our training\n",
    "- These include words like `the` or `and` or `a` that are not very important\n",
    "    - We will also use the English stop words form the standard sklearn package\n",
    "- Fit new `CountVectorizer` with these stop words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:32.358869Z",
     "start_time": "2018-09-22T05:57:32.350245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create our own stop words list & remove unimportant words such as 'the' or 'and'\n",
    "# Also, let's use the sklearn ENGLISH_STOP_WORDS, and unionize these to create the last stop words list\n",
    "\n",
    "my_stop_words = ['the', 'of', 'and', 'in', 'a', 'with', 'to', \n",
    "              'were', 'wa', 'for', 'or', 'is', 'by', 'that', \n",
    "              'than', 'from', 'at', 'an', 'this', 'be', 'had'\n",
    "             'after', 'on', 'p', 'are', 'these', 'we', 'have', 'may', \n",
    "              'it', 'who', 'pm', 'am', 'patient', 's', 'aa', 'll', 're', 'date',\n",
    "              'as', 'o', 'wa']\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:32.367050Z",
     "start_time": "2018-09-22T05:57:32.362012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 322 stop words\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:49:54.425521Z",
     "start_time": "2018-09-22T05:49:42.992365Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(tokenizer = tokenizer, \n",
    "                       stop_words = stop_words)\n",
    "count_vec.fit(train_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:50:16.540744Z",
     "start_time": "2018-09-22T05:49:54.427401Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vec.transform(train_df['Abstract'].values)\n",
    "X_test_count = count_vec.transform(train_df['Abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:57:49.451010Z",
     "start_time": "2018-09-22T05:57:32.369710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset({'more', 'become', 'system', 'hereby', 'twenty', 'p', 'go', 'became', 'onto', 'must', 'over', 'how', 'also', 'after', 'everywhere', 'him', 'next', 'whom', 'our', 'hadafter', 'seems', 'three', 'whose', 'nor', 'about', 'now', 'front', 'ten', 'himself', 'on', 'seemed', 'being', 'mo..., 'top', 'serious', 'call', 'last', 'nowhere', 'hers', 'is', 'first', 'wherein', 'somewhere', 'we'}),\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizer at 0x12091dae8>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using idf\n",
    "# tfidf_vec = TfidfVectorizer(tokenizer = tokenizer, norm='l2', ngram_range=(1,3), max_df = 0.4,\n",
    "#                        stop_words = stop_words, use_idf=True)\n",
    "tfidf_vec = TfidfVectorizer(tokenizer = tokenizer, norm='l2', ngram_range=(1,2), stop_words = stop_words)\n",
    "tfidf_vec.fit(train_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:18.350713Z",
     "start_time": "2018-09-22T05:57:49.453536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.transform(train_df['Abstract'].values)\n",
    "X_test_tfidf = tfidf_vec.transform(train_df['Abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:18.358593Z",
     "start_time": "2018-09-22T05:58:18.353578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14438, 661860)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:18.366529Z",
     "start_time": "2018-09-22T05:58:18.362304Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_tfidf[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:18.375124Z",
     "start_time": "2018-09-22T05:58:18.370010Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Just to check\n",
    "# tfidf_vec.inverse_transform(X_train_tfidf[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:18.381812Z",
     "start_time": "2018-09-22T05:58:18.378572Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = train_df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:18.387680Z",
     "start_time": "2018-09-22T05:58:18.383552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:10:01.659956Z",
     "start_time": "2018-09-22T05:10:01.656699Z"
    }
   },
   "outputs": [],
   "source": [
    "# # adding \"features\" columns as SparseSeries\n",
    "# for i, col in enumerate(tfidf_vec.get_feature_names()):\n",
    "#     train_df[col] = pd.SparseSeries(X_train_tfidf[:, i].toarray().ravel(), fill_value=0)\n",
    "#     test_df[col] = pd.SparseSeries(X_test_tfidf[:, i].toarray().ravel(), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:10:01.664253Z",
     "start_time": "2018-09-22T05:10:01.661719Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.drop('Abstract', axis=1, inplace=True)\n",
    "# test_df.drop('Abstract', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-NN classifier\n",
    "\n",
    "- KNN is a lazy, nonparametric, instance based classifier \n",
    "- Let's first define some standard distance / similiarity metrics (We will use the sklearn implementation)\n",
    "    - Euclidean\n",
    "    - Jaccard\n",
    "        - Good when text is lemmatized and CountVectorizer is used\n",
    "        - Number of words that appear in a document are weighted the same and have no effect on this metric\n",
    "    - Cosine\n",
    "        - Good when using bag of words with tf-idf\n",
    "        - Have to normalize vectors when using cosine similarity\n",
    "    - Hamming distance\n",
    "        - Good for text classification\n",
    "    - Levenhstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:55:49.029502Z",
     "start_time": "2018-09-22T06:55:49.007553Z"
    }
   },
   "outputs": [],
   "source": [
    "def csr_l2normalize(mat, copy=False):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm.\n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "\n",
    "    if copy is True:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:55:49.493515Z",
     "start_time": "2018-09-22T06:55:49.345528Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(i1, i2):\n",
    "    '''Calcualte Euclidean distance of two vectors'''\n",
    "    distance = math.sqrt(sum(pow(a-b, 2) for a, b in zip(i1, i2)))\n",
    "    return distance\n",
    "\n",
    "def two_norm(x): \n",
    "    '''Calculates the two norm of a vector'''\n",
    "    return math.sqrt(sum([a*a for a in x]))\n",
    "\n",
    "def cosine_distance(i1, i2):\n",
    "    '''Calculate cosine distance of two vectors'''\n",
    "    # Calculate dot product\n",
    "    numerator = sum(a*b for a,b in zip(i1,i2))\n",
    "    # Calculate norm of each instance\n",
    "    denominator = two_norm(i1)*two_norm(i2)\n",
    "    cos_dist = 1.0 - float(numerator)/float(denominator)\n",
    "    return cos_dist\n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "def two_norm_sparse(x): \n",
    "    '''Calculates the two norm of a sparse matrix'''\n",
    "#     two_norm = np.sqrt(x.multiply(x).sum(1))\n",
    "    two_norm = np.sqrt(x.multiply(x).sum(1))\n",
    "#     print(two_norm)\n",
    "    return two_norm\n",
    "    \n",
    "\n",
    "def cosine_similarity_sparse(s1, s2):\n",
    "    '''Calculate cosine similiarity of two sparse matrices'''\n",
    "    # Calculate dot product\n",
    "    numerator = s1.dot(s2.T)\n",
    "    # Calculate norm of each instance\n",
    "#     denominator = two_norm_sparse(s1) * (two_norm_sparse(s2))\n",
    "#     print(denominator)\n",
    "    return numerator\n",
    "#     return numerator/denominator\n",
    "\n",
    "def cosine_distance_sparse(s1, s2):\n",
    "    '''Calculate cosine distance of two sparse matrices'''\n",
    "    # Calculate dot product\n",
    "    numerator = s1.dot(s2.T)\n",
    "    if s1.shape[0] > s2.shape[0]:\n",
    "        one_array = np.ones((s1.shape[0], 1), dtype=float)\n",
    "    else:\n",
    "        one_array = np.ones((s2.shape[0], 1), dtype=float)\n",
    "    # Calculate norm of each instance\n",
    "    denominator = two_norm_sparse(s1) * (two_norm_sparse(s2))\n",
    "#     print(denominator)\n",
    "    return csr_matrix(one_array - (numerator/denominator))\n",
    "#     return numerator/denominator\n",
    "\n",
    "def euclidean_distance_sparse(s1, s2):\n",
    "    '''Calcualte Euclidean distance of two sparse matrices'''\n",
    "    \n",
    "    i1 = s1.toarray()\n",
    "    i2 = s2.toarray()\n",
    "    d = csr_matrix(i1 - i2)\n",
    "    d = two_norm_sparse(d)\n",
    "#     d = np.sqrt(np.sum(np.power(i1 - i2, 2), axis=1, keepdims=True))\n",
    "    return csr_matrix(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:55:49.712609Z",
     "start_time": "2018-09-22T06:55:49.709840Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:56:12.865341Z",
     "start_time": "2018-09-22T06:56:12.862284Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:51:00.512078Z",
     "start_time": "2018-09-22T05:51:00.510259Z"
    }
   },
   "outputs": [],
   "source": [
    "# euclidean_distance_sparse(X_train_tfidf[0:30], X_train_tfidf[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:51:00.516354Z",
     "start_time": "2018-09-22T05:51:00.513713Z"
    }
   },
   "outputs": [],
   "source": [
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'euclidean')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'cosine')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'jaccard')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'hamming')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'mahalanobis', VI=None)\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'chebyshev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:51:00.520422Z",
     "start_time": "2018-09-22T05:51:00.518127Z"
    }
   },
   "outputs": [],
   "source": [
    "# euclidean_distance_sparse(X_train_tfidf[0:30], X_train_tfidf[50]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:51:00.524106Z",
     "start_time": "2018-09-22T05:51:00.522032Z"
    }
   },
   "outputs": [],
   "source": [
    "# cosine_distance_sparse(X_train_tfidf[0:30], X_train_tfidf[50]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:56:15.728538Z",
     "start_time": "2018-09-22T06:56:15.680461Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_condition(train, labels, instance, K=5, metric = 'cosine'):\n",
    "    '''Using a distance metric to classify an instance'''\n",
    "    if metric == 'cosine':\n",
    "#         dots = cosine_similarity_sparse(instance, train)\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "#         reverse = True\n",
    "    elif metric == 'euclidean':\n",
    "        dots = euclidean_distance_sparse(train, instance)\n",
    "#         dots = csr_matrix(euclidean_distances(train.toarray(), instance.toarray()))\n",
    "#         dots = csr_matrix(cdist(train.toarray(), instance.toarray(), 'euclidean'))\n",
    "#         reverse = False\n",
    "    # Edit below later on\n",
    "    elif metric == 'jaccard':\n",
    "        dots = csr_matrix(cdist(train.toarray(), instance.toarray(), 'jaccard'))\n",
    "    else:\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "        \n",
    "        \n",
    "#     print(dots.indptr)\n",
    "    neighbors = list(zip(dots.indptr, dots.data))\n",
    "    if len(neighbors) == 0:\n",
    "        # could not find any neighbors\n",
    "        print('Could not find any neighbors.... Choosing a random one')\n",
    "        return np.asscalar(np.random.randint(low=1, high=5, size=1))\n",
    "    neighbors.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "#     print(neighbors[:K])\n",
    "    tc = Counter(labels[s[0]] for s in neighbors[:K]).most_common(5)\n",
    "#     print(tc)\n",
    "    if len(tc) < 5 or tc[0][1] > tc[1][1]:\n",
    "        # majority vote\n",
    "        return tc[0][0]\n",
    "    # tie break\n",
    "    tc = defaultdict(float)\n",
    "    for s in neighbors[:K]:\n",
    "        tc[labels[s[0]]] += s[1]\n",
    "#     print(tc)\n",
    "    return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:56:16.320156Z",
     "start_time": "2018-09-22T06:56:16.300943Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(features, labels, fold_num = 1, fold=10):\n",
    "    n = features.shape[0]\n",
    "    fold_size = int(np.ceil(n*1.0/fold))\n",
    "    feats = []\n",
    "    cls_train = []\n",
    "    for f in range(fold):\n",
    "        if f+1 != fold_num:\n",
    "            feats.append(features[f*fold_size: min((f+1)*fold_size, n)])\n",
    "            cls_train.extend(labels[f*fold_size: min((f+1)*fold_size, n)])\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(feats, format='csr')\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "    test = features[(fold_num-1)*fold_size: min(fold_num*fold_size, n), :]\n",
    "    cls_test = labels[(fold_num-1)*fold_size: min(fold_num*fold_size, n)]\n",
    "    return train, cls_train, test, cls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:56:16.876666Z",
     "start_time": "2018-09-22T06:56:16.834939Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(features, labels, metric='cosine', K=3, fold=10):\n",
    "    '''Using KFold Cross Validation to evaluate model accuracy'''\n",
    "    if metric not in ['cosine', 'euclidean', 'jaccard', 'hamming', 'mahalanobis']:\n",
    "        raise ValueError('Metric must be `cosine`, `euclidean`, or `jaccard`')\n",
    "    \n",
    "    macc = 0.0\n",
    "    cum_f1 = 0.0\n",
    "#     features = csr_l2normalize(features, copy=True)\n",
    "    for f in range(fold):\n",
    "        # split data into training and testing\n",
    "        train_set, train_labels, test_set, test_labels = split_data(features, labels, f+1, fold)\n",
    "        # predict the class of each test sample\n",
    "        predictions = [classify_condition(train_set, train_labels, test_set[i,:], K=K, metric=metric) \n",
    "                       for i in range(test_set.shape[0])]\n",
    "#         for i in range(test_set.shape[0]):\n",
    "#             neighbors = nearest_neighbors(train_set, train_labels, test_set[i, :], K = K)\n",
    "#             predictions = [classify(train_labels, neighbors) for i in range(test.shape[0]) ]\n",
    "#         print(test_labels)\n",
    "        # compute the accuracy of the prediction\n",
    "        acc = 0.0\n",
    "        for i in range(len(test_labels)):\n",
    "            if test_labels[i] == predictions[i]:\n",
    "                acc += 1\n",
    "        acc /= len(test_labels)\n",
    "        f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "#         print('Fold-%i Accuracy: %.05f' % (f+1, acc))\n",
    "        print('Fold-%i F1 Score: %.05f' % (f+1, f1))\n",
    "        macc += acc\n",
    "        cum_f1 += f1\n",
    "    \n",
    "    return macc/float(fold), cum_f1/float(fold)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T07:14:53.220544Z",
     "start_time": "2018-09-22T06:56:48.275433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1 F1 Score: 0.60300\n",
      "Fold-2 F1 Score: 0.59791\n",
      "Fold-3 F1 Score: 0.63220\n",
      "Fold-4 F1 Score: 0.61925\n",
      "Fold-5 F1 Score: 0.58172\n",
      "Fold-6 F1 Score: 0.60622\n",
      "Fold-7 F1 Score: 0.60755\n",
      "Fold-8 F1 Score: 0.60413\n",
      "Fold-9 F1 Score: 0.62200\n",
      "Fold-10 F1 Score: 0.59989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6073875400440121"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, f = evaluate_model(X_train_tfidf, Y_train, metric = 'cosine', K=42, fold=10)\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:54:12.136550Z",
     "start_time": "2018-09-22T05:54:06.559068Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "scores = cross_val_score(knn, X_train_tfidf, Y_train, cv=10, scoring='f1_weighted', n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:54:12.146553Z",
     "start_time": "2018-09-22T05:54:12.139950Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T05:58:30.419589Z",
     "start_time": "2018-09-22T05:58:30.413301Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "k_grid = np.arange(1, 140, 10)\n",
    "param_grid = {'n_neighbors': k_grid}\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10, scoring='f1_weighted', n_jobs=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:07:49.166996Z",
     "start_time": "2018-09-22T05:59:09.196435Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.3805840630673704, total=   1.3s\n",
      "[CV] .......... n_neighbors=1, score=0.3827546597713373, total=   1.3s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ......... n_neighbors=1, score=0.35192318911214887, total=   1.4s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ......... n_neighbors=1, score=0.39803480270008823, total=   1.2s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ......... n_neighbors=1, score=0.37187592389598884, total=   1.2s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ......... n_neighbors=1, score=0.35761904127947436, total=   1.2s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.3794013688937698, total=   1.4s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.3659819814186253, total=   1.4s\n",
      "[CV] .......... n_neighbors=1, score=0.3896188693565267, total=   1.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] .......... n_neighbors=1, score=0.3583655643564242, total=   1.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5559746531202342, total=   1.3s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] .......... n_neighbors=11, score=0.560569604526177, total=   1.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5804869462120108, total=   1.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5832563093513479, total=   1.3s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5627952504172519, total=   1.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5515998818813941, total=   1.3s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] .......... n_neighbors=11, score=0.576522009149685, total=   1.3s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5823512536100248, total=   1.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5889316886648546, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5736212988642274, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5782225454947152, total=   1.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5918718731507003, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5998055534246253, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.6066803840756485, total=   1.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5792322378273482, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5756244439239938, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=21, score=0.5987692515985877, total=   1.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5852399636106745, total=   1.1s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.6115427005705056, total=   1.1s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ........... n_neighbors=21, score=0.59409452109336, total=   1.1s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.5928058884997991, total=   1.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] .......... n_neighbors=31, score=0.592360105808841, total=   1.1s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6194582687572691, total=   1.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6137793966161416, total=   1.4s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.5882445010528103, total=   1.3s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6012790570003035, total=   1.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6065861992606368, total=   1.3s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6030406919775891, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6205528808408997, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6022897448374638, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.5967805282318522, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6032280480350599, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6244720388800459, total=   1.4s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6195512447645095, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.5887855704107899, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6073358433013376, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6056894272598765, total=   1.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6073593718743865, total=   1.3s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6194408553033478, total=   1.3s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6024407892055155, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6062132870850029, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6025149650962539, total=   1.7s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6279947449913248, total=   1.4s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6220628630733208, total=   1.4s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ........... n_neighbors=51, score=0.58888119832586, total=   1.4s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6023181045414311, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6048535806969688, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.5957147298302888, total=   1.6s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.623181713736663, total=   1.3s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6030991538304172, total=   1.5s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6036384789074699, total=   1.4s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6030336181597833, total=   1.2s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6280349570095226, total=   1.2s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6215551116282093, total=   1.3s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.5819979026758297, total=   1.1s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6019537140885552, total=   1.2s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6033797272704315, total=   1.3s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6056412912903036, total=   1.2s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] .......... n_neighbors=61, score=0.617942066985841, total=   1.2s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6070634034163607, total=   1.3s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6017659255150076, total=   1.4s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6002480281032019, total=   1.3s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6245009673702602, total=   1.7s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6117224114028856, total=   1.5s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.5909795737245581, total=   1.4s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.5967196074191199, total=   1.8s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] .......... n_neighbors=71, score=0.608260269433764, total=   1.4s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6102174781955968, total=   1.4s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6193791384391377, total=   1.5s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.5939258720969179, total=   1.2s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6032105341421147, total=   1.2s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6008801087580564, total=   2.0s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6235917298730722, total=   1.6s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6131375434632139, total=   1.5s\n",
      "[CV] n_neighbors=81 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=81, score=0.5935893652529867, total=   1.6s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.5974027620593263, total=   1.3s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6052609385970358, total=   1.3s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6120017594871892, total=   1.5s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6168292154088842, total=   1.4s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] .......... n_neighbors=81, score=0.589766799573471, total=   1.2s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6015067993662244, total=   1.4s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6028750609707314, total=   1.2s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6224168986270657, total=   1.2s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] .......... n_neighbors=91, score=0.612804859433944, total=   1.4s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] .......... n_neighbors=91, score=0.588947401861245, total=   1.2s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.5962713267985775, total=   1.2s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6087230313872548, total=   1.4s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6064898389112906, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6176333962664663, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ......... n_neighbors=91, score=0.5878672545239001, total=   1.4s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5980328944580182, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5949993241189578, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6164877778448821, total=   1.4s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6081523303537366, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5851110534488959, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5922428723128641, total=   1.4s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6068926487850619, total=   1.2s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5985790870354604, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6149479796137715, total=   1.4s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5908625605211812, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.5922096529436995, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.5938798259631098, total=   1.4s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6167972341902425, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6101715879427055, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.5870790422724795, total=   1.4s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.5853810582485521, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ......... n_neighbors=111, score=0.606646283059907, total=   1.2s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6044932607772092, total=   1.4s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6169570249798816, total=   1.4s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.5787156828623266, total=   1.5s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5876682262081252, total=   1.4s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5985707183076939, total=   1.2s\n",
      "[CV] n_neighbors=121 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  7.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ n_neighbors=121, score=0.6208993752989813, total=   1.2s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6098443556450129, total=   1.4s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5828201516247669, total=   1.2s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5925847316255005, total=   1.2s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5974280853775459, total=   1.3s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6008974765646465, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6229661028074461, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5807793214778764, total=   1.4s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ......... n_neighbors=131, score=0.585734481898568, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6008259166560453, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6179830481875508, total=   1.3s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6164725585316253, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.5834023268680322, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.5852559739218598, total=   1.3s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ......... n_neighbors=131, score=0.597249080371336, total=   1.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6031010961100229, total=   1.2s\n",
      "[CV] ......... n_neighbors=131, score=0.618081764809263, total=   1.3s\n",
      "[CV] ........ n_neighbors=131, score=0.5791026768398899, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 140 out of 140 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'n_neighbors': array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:07:49.177084Z",
     "start_time": "2018-09-22T06:07:49.171019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 51}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:08:25.299604Z",
     "start_time": "2018-09-22T06:08:25.294351Z"
    }
   },
   "outputs": [],
   "source": [
    "k_grid = np.arange(40, 60, 1)\n",
    "param_grid = {'n_neighbors': k_grid}\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10, scoring='f1_weighted', n_jobs=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:20:37.501652Z",
     "start_time": "2018-09-22T06:08:32.394011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.5922019905671804, total=   1.4s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] .......... n_neighbors=40, score=0.628508064135783, total=   1.4s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.5959713300739028, total=   1.4s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.6188222145118719, total=   1.4s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.5873770416539499, total=   1.3s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.5994059755751412, total=   1.2s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.6051803106120087, total=   1.4s\n",
      "[CV] n_neighbors=40 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.6033323383341642, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=40, score=0.6187545902800715, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.5967805282318522, total=   1.3s\n",
      "[CV] .......... n_neighbors=40, score=0.600972449891373, total=   1.3s\n",
      "[CV] ......... n_neighbors=41, score=0.6032280480350599, total=   1.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6195512447645095, total=   1.3s\n",
      "[CV] ......... n_neighbors=41, score=0.6244720388800459, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.5887855704107899, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6073593718743865, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6073358433013376, total=   1.4s\n",
      "[CV] ......... n_neighbors=41, score=0.6056894272598765, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6194408553033478, total=   1.4s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6015521808737996, total=   1.3s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6024407892055155, total=   1.3s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] .......... n_neighbors=42, score=0.601796694375316, total=   1.3s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6260536346890839, total=   1.3s\n",
      "[CV] ......... n_neighbors=42, score=0.6167924960813099, total=   1.2s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] .......... n_neighbors=42, score=0.588205957341136, total=   1.4s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6078085204967639, total=   1.3s\n",
      "[CV] ......... n_neighbors=42, score=0.6026248116622731, total=   1.3s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] n_neighbors=42 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_neighbors=42, score=0.606406714330781, total=   1.4s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] .......... n_neighbors=42, score=0.600396127738642, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6263096743762426, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.5924147505449702, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6006151607541685, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6223960907274739, total=   1.2s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6141888742604622, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.5837705041921503, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6037496474389226, total=   1.2s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6064910103447602, total=   1.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6046213586897168, total=   1.3s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6230632659824769, total=   1.2s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.5996792876185904, total=   1.3s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.5973075350360036, total=   1.3s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.5991865229762084, total=   1.2s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] .......... n_neighbors=44, score=0.622467327713553, total=   1.4s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6146643699357422, total=   1.5s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.5862157417345533, total=   1.5s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6068548587789452, total=   1.2s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6108683587147893, total=   1.3s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6020305733275171, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6239410007235386, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6024511921539228, total=   1.3s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6034205217511203, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.5999226416905866, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6233315449311806, total=   1.3s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6147010286891245, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.5875636146130895, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] .......... n_neighbors=45, score=0.603852697860008, total=   1.3s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6062391356308761, total=   1.2s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6006808309109335, total=   1.1s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6180030185915523, total=   1.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6030508618998461, total=   1.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6011408295750571, total=   1.1s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] .......... n_neighbors=46, score=0.600071951303324, total=   1.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6229651694301571, total=   1.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6175356235687666, total=   1.1s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.5850672638281236, total=   1.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] .......... n_neighbors=46, score=0.603438874929436, total=   1.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6055035377031578, total=   1.1s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6038265229335513, total=   1.2s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6241105357029584, total=   1.2s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.5984867271190386, total=   1.1s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.5976605014267107, total=   1.2s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.5975868070337386, total=   1.2s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6205982369110632, total=   1.3s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] .......... n_neighbors=47, score=0.616043441819502, total=   1.4s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.5895321851545419, total=   1.4s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6006051466740749, total=   1.1s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] .......... n_neighbors=47, score=0.607914825199159, total=   1.2s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ............ n_neighbors=47, score=0.6007665346453, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6221004415783751, total=   1.1s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6064537453754355, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6042707999837261, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.5998687265204623, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6227583100541301, total=   1.4s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6169410143323816, total=   1.3s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.5839705326161944, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=48, score=0.6010389622851747, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6070944913670104, total=   1.2s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] .......... n_neighbors=48, score=0.598089094162048, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6197007808974869, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6041329906583174, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6039311271776224, total=   1.1s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] .......... n_neighbors=49, score=0.600699925421494, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6237554489603443, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6189000731324854, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.5868049888178646, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6007405874623909, total=   1.2s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6066023144760485, total=   1.1s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.5951841749718827, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6215288484692024, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6022007557939436, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.5999858403110492, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.5996117727590292, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6248252372130948, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6235285115083586, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] .......... n_neighbors=50, score=0.585837169681934, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6006454011018078, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6090747411884346, total=   1.2s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.5958979278550093, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6207716713466543, total=   1.3s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.5985832259877222, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6062132870850029, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6025149650962539, total=   1.3s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6279947449913248, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6220628630733208, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ........... n_neighbors=51, score=0.58888119832586, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6023181045414311, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6048535806969688, total=   1.2s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.5957147298302888, total=   1.3s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.623181713736663, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6030991538304172, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] .......... n_neighbors=52, score=0.605125838880636, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] .......... n_neighbors=52, score=0.602880895050906, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  7.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=52, score=0.6181830867219213, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6229241169894809, total=   1.3s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.5909659583658198, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6004539793614939, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6078832836361808, total=   1.2s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] .......... n_neighbors=52, score=0.593489099504249, total=   1.1s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] .......... n_neighbors=52, score=0.619061863681087, total=   1.2s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6006183252188567, total=   1.2s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6053277796497557, total=   1.1s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.5988934769365996, total=   1.2s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] .......... n_neighbors=53, score=0.622405387563158, total=   1.2s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6210092558055154, total=   1.2s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.5902888366020551, total=   1.2s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6031507045018041, total=   1.3s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6100955679377795, total=   1.1s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.5936546312099773, total=   1.2s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6194726404495396, total=   1.3s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.5951618866299224, total=   1.1s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ........... n_neighbors=54, score=0.60676136816653, total=   1.1s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.5992287930309868, total=   1.3s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ........... n_neighbors=54, score=0.62717242194661, total=   1.1s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6214310619525532, total=   1.2s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.5866378860912654, total=   1.3s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6018596699107813, total=   1.2s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6060967172037005, total=   1.2s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.5965687364978939, total=   1.3s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6226222815407468, total=   1.1s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.5999511733591861, total=   1.2s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6033532274258655, total=   1.3s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6013060172981931, total=   1.1s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6278416854508629, total=   1.2s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] .......... n_neighbors=55, score=0.622051705799535, total=   1.3s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.5886171461026853, total=   1.1s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] .......... n_neighbors=55, score=0.603621813189308, total=   1.2s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6056673419896045, total=   1.3s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.5954886514762512, total=   1.1s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6178815596264667, total=   1.1s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6009886764527279, total=   1.3s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6046993208445102, total=   1.2s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6038226251125646, total=   1.2s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6271620754334192, total=   1.3s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6202446070913943, total=   1.1s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.5913440784175097, total=   1.2s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6024922215755938, total=   1.3s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6049558573936259, total=   1.1s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.5940098584396674, total=   1.2s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6174013379535167, total=   1.3s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.5981798343098186, total=   1.1s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6055748291407244, total=   1.2s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] .......... n_neighbors=57, score=0.603203233944366, total=   1.3s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6305576821054142, total=   1.1s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6218502468030875, total=   1.2s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.5896729331858864, total=   1.3s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6000913990402443, total=   1.1s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6018102734644251, total=   1.2s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.5973723832551376, total=   1.3s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6194816808874407, total=   1.1s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6001932053563297, total=   1.2s\n",
      "[CV] n_neighbors=58 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=58, score=0.6049634457778313, total=   1.3s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6071252627868733, total=   1.1s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6263632396905706, total=   1.2s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6236717724533882, total=   1.3s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.5900733971972225, total=   1.1s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6023080515754863, total=   1.2s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6016348237884225, total=   1.2s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.5978023877183509, total=   1.1s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6180420771630172, total=   1.2s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6049880718747584, total=   1.2s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6070528822107565, total=   1.1s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6074062547293003, total=   1.2s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6270318143187675, total=   1.2s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6205575796853074, total=   1.1s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.5869942855045143, total=   1.2s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6047374274008116, total=   1.2s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.5998573083129672, total=   1.1s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.5977018693411821, total=   1.2s\n",
      "[CV] ......... n_neighbors=59, score=0.6195164047176112, total=   1.2s\n",
      "[CV] ......... n_neighbors=59, score=0.6054536334509876, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'n_neighbors': array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
       "       57, 58, 59])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:20:37.509000Z",
     "start_time": "2018-09-22T06:20:37.504809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 42}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T06:56:02.074272Z",
     "start_time": "2018-09-22T06:56:02.070045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6077950723422624"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:53:12.626276Z",
     "start_time": "2018-09-22T03:48:10.373Z"
    }
   },
   "outputs": [],
   "source": [
    "best_f1 = 0.0\n",
    "best_k = None\n",
    "best_acc = 0.0\n",
    "\n",
    "# sqrt(# of training records) ~ 140  \n",
    "for k in np.arange(1, 140, 5):\n",
    "    acc, f1 = evaluate_model(X_train_tfidf, Y_train, K=k, fold=10)\n",
    "#     print('For %i-NN, 10-Fold CV Average Accuracy: %.05f%%' % (k, acc * 100.0)) \n",
    "    print('For %i-NN, 10-Fold CV Weighted F1 Score: %.05f' % (k, f1)) \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_acc = acc\n",
    "        best_k = k\n",
    "    \n",
    "print('Best Model Params: \\n For %i-NN, 10-Fold CV Weighted F1 Score: %.08f' (best_k, best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
