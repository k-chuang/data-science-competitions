{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR1: Medical Text Classification\n",
    "\n",
    "* Author: Kevin Chuang [@k-chuang](https://www.github.com/k-chuang)\n",
    "* Created on: September 21, 2018\n",
    "* Description: Given a medical abstract, classify condition of patient (5 classes) using K-Nearest Neighbors.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:35.825084Z",
     "start_time": "2018-09-24T07:43:34.425368Z"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Text Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Utilities\n",
    "import string\n",
    "import math\n",
    "from operator import itemgetter \n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20.0, 10.0), \"axes.labelsize\": 14})\n",
    "\n",
    "# sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.298499Z",
     "start_time": "2018-09-24T07:43:35.827833Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.dat', sep='\\t', header=None, names=['Label', 'Abstract'])\n",
    "test_df = pd.read_csv('data/test.dat', sep='\\t', header=None, names=['Abstract'])\n",
    "submission_df = pd.read_csv('data/format.dat', header=None, names=['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.316383Z",
     "start_time": "2018-09-24T07:43:36.300831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Catheterization laboratory events and hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Renal abscess in children. Three cases of rena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hyperplastic polyps seen at sigmoidoscopy are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Subclavian artery to innominate vein fistula a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Effect of local inhibition of gamma-aminobutyr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Abstract\n",
       "0      4  Catheterization laboratory events and hospital...\n",
       "1      5  Renal abscess in children. Three cases of rena...\n",
       "2      2  Hyperplastic polyps seen at sigmoidoscopy are ...\n",
       "3      5  Subclavian artery to innominate vein fistula a...\n",
       "4      4  Effect of local inhibition of gamma-aminobutyr..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.327765Z",
     "start_time": "2018-09-24T07:43:36.318666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excision of limbal dermoids. We reviewed the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bell's palsy. A diagnosis of exclusion. In cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retained endobronchial foreign body removal fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recurrent buccal space abscesses: a complicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intracranial fibromatosis. Fibromatoses are un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract\n",
       "0  Excision of limbal dermoids. We reviewed the c...\n",
       "1  Bell's palsy. A diagnosis of exclusion. In cas...\n",
       "2  Retained endobronchial foreign body removal fa...\n",
       "3  Recurrent buccal space abscesses: a complicati...\n",
       "4  Intracranial fibromatosis. Fibromatoses are un..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "- View a sample of the medical abstract text\n",
    "- Read through it, and I definitely had to Google some terminology\n",
    "    - Initial observations of medical abstract text\n",
    "        - There are a lot of complex medical terms (e.g. acute myocardial infarction) \n",
    "        - There seems to be a lot of n = some integer (e.g. n = 100)\n",
    "        - There seems to be a lot of percentages (e.g. 55%)\n",
    "- Imbalanced Classes\n",
    "    - Conventional algorithms are often biased towards the majority class, not taking the data distribution into consideration.\n",
    "    - Need configure model or artifically balance the dataset (oversampling under-represented classes and undersampling over-represented classes)\n",
    "- Classes?\n",
    "    - 1: Neoplasms\n",
    "    - 2: Digestive System Diseases\n",
    "    - 3: Nervous System Diseases\n",
    "    - 4: Cardiovascular Diseases\n",
    "    - 5: General Pathological conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.338670Z",
     "start_time": "2018-09-24T07:43:36.330416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null abstracts\n",
    "train_df.Abstract.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.348965Z",
     "start_time": "2018-09-24T07:43:36.342432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null labels\n",
    "train_df.Label.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.358100Z",
     "start_time": "2018-09-24T07:43:36.351321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.364710Z",
     "start_time": "2018-09-24T07:43:36.360384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Renal abscess in children. Three cases of renal abscesses in children are described to illustrate the variable presenting features. An additional 23 pediatric cases, reported over the past ten years, were reviewed for clinical features and therapy. Fever, loin pain, and leukocytosis were common presenting features, but less than half of all abscesses were associated with either an abnormal urinalysis or a positive urine culture. The presenting features were sometimes confused with appendicitis, peritonitis, or a Wilms tumor. An organism was identified in 17 cases--Escherichia coli in 9 children and Staphylococcus aureus in 8 children. The majority of E. coli infections occurred in girls and the majority of S. aureus infections occurred in boys. Reflux was documented in 5 patients, and 2 children had a possible extrarenal source of infection. Antibiotics alone produced a cure in 10 children (38%), but 16 children (62%) required a surgical procedure. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Abstract'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.373963Z",
     "start_time": "2018-09-24T07:43:36.366864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4805\n",
       "1    3163\n",
       "4    3051\n",
       "3    1925\n",
       "2    1494\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalanced classes\n",
    "\n",
    "train_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.519184Z",
     "start_time": "2018-09-24T07:43:36.375753Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the imbalanced classes\n",
    "sns.countplot(x='Label', data=train_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Going to use `Bag of Words` approach\n",
    "    - presence of words (frequency or count) is taken into consideration & order is ignored\n",
    "    - BOW basically breaks up the note into the individual words and counts how many times each word occurs.\n",
    "- Tokenizer and a vectorizer. \n",
    "    - The tokenizer breaks a single abstract into a list of words and a vectorizer takes a list of words and counts the words.\n",
    "- `Tokenizer`:\n",
    "    - Remove punctuation & numbers\n",
    "    - Lowercase everything\n",
    "    - Two approaches for tokenization\n",
    "        - Goal is reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "        - Lemmatize all the text (e.g. women will become woman)\n",
    "            - Lemmatization is the process of converting the words of a sentence to its dictionary form. \n",
    "        - Stem all the text\n",
    "            - Stemming is the process of converting words to the stem (root) of the word\n",
    "- `Vectorizer`:\n",
    "    - General process of turning a collection of text documents into numerical feature vectors. \n",
    "    - This specific strategy (tokenization, counting and normalization) is called the Bag of Words or “Bag of n-grams” representation. \n",
    "    - Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "    - `CountVectorizer`\n",
    "        - Encodes a vector with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "        - `vocabulary_` is a dict/mapping of the terms to their indices in the document-term matrix, not the counts.\n",
    "    - `TfidfVectorizer`\n",
    "        - Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "            - Normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents.\n",
    "        - TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "            - *This can be extremely useful for this problem, since we have 5 categories we are trying to classify and thus certain categories (medical conditions) may have words in the medical abstract that are unique to the condition*\n",
    "        - The resulting tf-idf vectors are then normalized by the Euclidean norm (L2)\n",
    "        - **Since the medical text data have a lot of multi-word expressions (e.g. *left anterior descending coronary artery*), I will use N-grams (where N >= 1) to keep the local positioning of these important words **\n",
    "            - Experimented with N-grams, and it seems 1-gram, 2-gram, 3-gram, and 4-grams produce best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.575019Z",
     "start_time": "2018-09-24T07:43:36.521202Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    # Use Lemma tokenizer to tokenize the words\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lemmas = [lemma.lemmatize(word.strip()) for word in text.split()]\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "def word_tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def stem_tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    # Best Stemmer for this dataset (Tested)\n",
    "    stemmer = PorterStemmer()\n",
    "#     stemmer = SnowballStemmer(\"english\")\n",
    "#     stemmer = LancasterStemmer()\n",
    "    stems = [stemmer.stem(word.strip()) for word in text.split()]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:43:36.584207Z",
     "start_time": "2018-09-24T07:43:36.576870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['renal', 'abscess', 'in', 'children', 'three', 'case', 'of', 'renal', 'abscess', 'in', 'children', 'are', 'describ', 'to', 'illustr', 'the', 'variabl', 'present', 'featur', 'an', 'addit', 'pediatr', 'case', 'report', 'over', 'the', 'past', 'ten', 'year', 'were', 'review', 'for', 'clinic', 'featur', 'and', 'therapi', 'fever', 'loin', 'pain', 'and', 'leukocytosi', 'were', 'common', 'present', 'featur', 'but', 'less', 'than', 'half', 'of', 'all', 'abscess', 'were', 'associ', 'with', 'either', 'an', 'abnorm', 'urinalysi', 'or', 'a', 'posit', 'urin', 'cultur', 'the', 'present', 'featur', 'were', 'sometim', 'confus', 'with', 'append', 'periton', 'or', 'a', 'wilm', 'tumor', 'an', 'organ', 'wa', 'identifi', 'in', 'case', 'escherichia', 'coli', 'in', 'children', 'and', 'staphylococcu', 'aureu', 'in', 'children', 'the', 'major', 'of', 'e', 'coli', 'infect', 'occur', 'in', 'girl', 'and', 'the', 'major', 'of', 's', 'aureu', 'infect', 'occur', 'in', 'boy', 'reflux', 'wa', 'document', 'in', 'patient', 'and', 'children', 'had', 'a', 'possibl', 'extraren', 'sourc', 'of', 'infect', 'antibiot', 'alon', 'produc', 'a', 'cure', 'in', 'children', 'but', 'children', 'requir', 'a', 'surgic', 'procedur']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(train_df['Abstract'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.141845Z",
     "start_time": "2018-09-24T07:43:36.586592Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(tokenizer = tokenizer)\n",
    "vec.fit(train_df['Abstract'])\n",
    "X_train = vec.transform(train_df['Abstract'])\n",
    "# abstract_df = vec.fit_transform(train_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.146421Z",
     "start_time": "2018-09-24T07:45:11.144155Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.155433Z",
     "start_time": "2018-09-24T07:45:11.148500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size is around 31869 unique words\n",
    "\n",
    "len(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.186105Z",
     "start_time": "2018-09-24T07:45:11.158404Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_names = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.192554Z",
     "start_time": "2018-09-24T07:45:11.187915Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts = np.asarray(X_train.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.200221Z",
     "start_time": "2018-09-24T07:45:11.194416Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_counts_df = pd.DataFrame.from_dict({'Word':vocab_names, 'Counts':word_counts.ravel()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.209522Z",
     "start_time": "2018-09-24T07:45:11.202591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>44086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aab</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaem</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Counts\n",
       "0     a   44086\n",
       "1    aa      28\n",
       "2   aaa      27\n",
       "3   aab       7\n",
       "4  aaem       3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.227101Z",
     "start_time": "2018-09-24T07:45:11.211342Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22066</th>\n",
       "      <td>the</td>\n",
       "      <td>122496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>of</td>\n",
       "      <td>121285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>and</td>\n",
       "      <td>81967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10379</th>\n",
       "      <td>in</td>\n",
       "      <td>79415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>44086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>with</td>\n",
       "      <td>43935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22352</th>\n",
       "      <td>to</td>\n",
       "      <td>43089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16369</th>\n",
       "      <td>patient</td>\n",
       "      <td>39336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24116</th>\n",
       "      <td>wa</td>\n",
       "      <td>28458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24246</th>\n",
       "      <td>were</td>\n",
       "      <td>24358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>for</td>\n",
       "      <td>21779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15665</th>\n",
       "      <td>or</td>\n",
       "      <td>15422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11120</th>\n",
       "      <td>is</td>\n",
       "      <td>14674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>by</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22064</th>\n",
       "      <td>that</td>\n",
       "      <td>14488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22063</th>\n",
       "      <td>than</td>\n",
       "      <td>13077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>from</td>\n",
       "      <td>10611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>be</td>\n",
       "      <td>9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>at</td>\n",
       "      <td>9905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>an</td>\n",
       "      <td>9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190</th>\n",
       "      <td>studi</td>\n",
       "      <td>9756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22118</th>\n",
       "      <td>thi</td>\n",
       "      <td>9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>as</td>\n",
       "      <td>9560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>had</td>\n",
       "      <td>9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>after</td>\n",
       "      <td>9296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15578</th>\n",
       "      <td>on</td>\n",
       "      <td>9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>group</td>\n",
       "      <td>8899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>cell</td>\n",
       "      <td>8682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>diseas</td>\n",
       "      <td>8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15237</th>\n",
       "      <td>not</td>\n",
       "      <td>8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23556</th>\n",
       "      <td>use</td>\n",
       "      <td>7889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16027</th>\n",
       "      <td>p</td>\n",
       "      <td>7810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11861</th>\n",
       "      <td>less</td>\n",
       "      <td>7486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>are</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24505</th>\n",
       "      <td>year</td>\n",
       "      <td>7160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22114</th>\n",
       "      <td>these</td>\n",
       "      <td>7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>case</td>\n",
       "      <td>6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24202</th>\n",
       "      <td>we</td>\n",
       "      <td>6368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22673</th>\n",
       "      <td>treatment</td>\n",
       "      <td>6343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19264</th>\n",
       "      <td>result</td>\n",
       "      <td>6061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10436</th>\n",
       "      <td>increas</td>\n",
       "      <td>6030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>effect</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>have</td>\n",
       "      <td>5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22886</th>\n",
       "      <td>tumor</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22928</th>\n",
       "      <td>two</td>\n",
       "      <td>5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>dure</td>\n",
       "      <td>5529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>arteri</td>\n",
       "      <td>5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15597</th>\n",
       "      <td>one</td>\n",
       "      <td>5332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>all</td>\n",
       "      <td>5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>clinic</td>\n",
       "      <td>5238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14577</th>\n",
       "      <td>no</td>\n",
       "      <td>5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>may</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>associ</td>\n",
       "      <td>4911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>control</td>\n",
       "      <td>4902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>but</td>\n",
       "      <td>4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18779</th>\n",
       "      <td>rate</td>\n",
       "      <td>4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11225</th>\n",
       "      <td>it</td>\n",
       "      <td>4675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>follow</td>\n",
       "      <td>4595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>blood</td>\n",
       "      <td>4562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24296</th>\n",
       "      <td>who</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Counts\n",
       "22066        the  122496\n",
       "15465         of  121285\n",
       "843          and   81967\n",
       "10379         in   79415\n",
       "0              a   44086\n",
       "24343       with   43935\n",
       "22352         to   43089\n",
       "16369    patient   39336\n",
       "24116         wa   28458\n",
       "24246       were   24358\n",
       "7886         for   21779\n",
       "15665         or   15422\n",
       "11120         is   14674\n",
       "2800          by   14561\n",
       "22064       that   14488\n",
       "22063       than   13077\n",
       "8026        from   10611\n",
       "2019          be    9972\n",
       "1593          at    9905\n",
       "787           an    9900\n",
       "21190      studi    9756\n",
       "22118        thi    9646\n",
       "1494          as    9560\n",
       "8768         had    9393\n",
       "415        after    9296\n",
       "15578         on    9213\n",
       "8668       group    8899\n",
       "3273        cell    8682\n",
       "5713      diseas    8125\n",
       "15237        not    8004\n",
       "23556        use    7889\n",
       "16027          p    7810\n",
       "11861       less    7486\n",
       "1385         are    7206\n",
       "24505       year    7160\n",
       "22114      these    7144\n",
       "3100        case    6867\n",
       "24202         we    6368\n",
       "22673  treatment    6343\n",
       "19264     result    6061\n",
       "10436    increas    6030\n",
       "6308      effect    5893\n",
       "8915        have    5886\n",
       "22886      tumor    5836\n",
       "22928        two    5659\n",
       "6068        dure    5529\n",
       "1441      arteri    5364\n",
       "15597        one    5332\n",
       "574          all    5294\n",
       "3842      clinic    5238\n",
       "14577         no    5214\n",
       "12662        may    5037\n",
       "1556      associ    4911\n",
       "4345     control    4902\n",
       "2772         but    4900\n",
       "18779       rate    4711\n",
       "11225         it    4675\n",
       "7868      follow    4595\n",
       "2406       blood    4562\n",
       "24296        who    4513"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_counts_df.sort_values(['Counts'], ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:11.988121Z",
     "start_time": "2018-09-24T07:45:11.228941Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the top 50 most frequently occurring words\n",
    "\n",
    "# Set the graph parameters\n",
    "sns.set(rc={\"figure.figsize\": (20.0, 10.0), \"axes.labelsize\": 18})\n",
    "\n",
    "top50 = vocab_counts_df.sort_values(['Counts'], ascending=False).iloc[:50]\n",
    "\n",
    "ax = sns.barplot(\"Word\", \"Counts\", data=top50, palette=\"Blues_d\");\n",
    "ax.set_title('Top 50 Words')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "- Stop words are words we do not want to use as features, and shall remove from our training\n",
    "- These include words like `the` or `and` or `a` that are not very important\n",
    "    - We will also use the English stop words form the standard sklearn package\n",
    "- Fit new `CountVectorizer` with these stop words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:12.014216Z",
     "start_time": "2018-09-24T07:45:11.990474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create our own stop words list & remove unimportant words such as 'the' or 'and'\n",
    "# Also, let's use the sklearn ENGLISH_STOP_WORDS, and unionize these to create the last stop words list\n",
    "\n",
    "my_stop_words = ['the', 'of', 'and', 'in', 'a', 'with', 'to', \n",
    "              'were', 'wa', 'for', 'or', 'is', 'by', 'that', \n",
    "              'than', 'from', 'at', 'an', 'this', 'be', 'had'\n",
    "             'after', 'on', 'p', 'are', 'these', 'we', 'have', 'may', \n",
    "              'it', 'who', 'pm', 'am', 'patient', 's', 'aa', 'll', 're', 'date',\n",
    "              'as', 'o', 'wa', 'year']\n",
    "\n",
    "extra_stop_words = ['the','and','to','of','was','with','a','on','in','for','name',\n",
    "                    'is','patient','s','he','at','as','or','one','she','his','her','am',\n",
    "                   'were','you','pt','pm','by','be','had','your','this','date', \n",
    "                   'from','there','an','that','p','are','have','has','h','but','o',\n",
    "                   'namepattern','which','every','also']\n",
    "\n",
    "# 153 stop words from NLTK\n",
    "nltk_stop_words = stopwords.words('english')\n",
    "# Combine stop words from all the stop word lists\n",
    "stop_words = ENGLISH_STOP_WORDS.union(my_stop_words).union(extra_stop_words).union(nltk_stop_words)\n",
    "# stop_words = ENGLISH_STOP_WORDS.union(nltk_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:12.019520Z",
     "start_time": "2018-09-24T07:45:12.015878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 328 stop words\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:45:56.831127Z",
     "start_time": "2018-09-24T07:45:12.021214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=frozenset({'from', 'hers', 'front', 'needn', 'well', 'bill', 'mostly', 'yours', 'whole', 'above', 'cant', 'aa', 'over', \"doesn't\", 'mill', 'much', 'always', 'nor', 'yourselves', 'same', 'ever', 'no', 'yourself', \"couldn't\", 'nine', 'had', 'hence', 'throughout', 'enough', \"didn't\", 'what',...l', \"you'll\", 'me', 'did', 'at', 'may', 'them', 'theirs', 'becoming', 'patient', 'should', \"don't\"}),\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizer at 0x11931bbf8>, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(tokenizer = tokenizer, \n",
    "                       stop_words = stop_words)\n",
    "count_vec.fit(train_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:47:29.035664Z",
     "start_time": "2018-09-24T07:45:56.835022Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vec.transform(train_df['Abstract'].values)\n",
    "X_test_count = count_vec.transform(train_df['Abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:48:32.897347Z",
     "start_time": "2018-09-24T07:47:29.037965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset({'from', 'hers', 'front', 'needn', 'well', 'bill', 'mostly', 'yours', 'whole', 'above', 'cant', 'aa', 'over', \"doesn't\", 'mill', 'much', 'always', 'nor', 'yourselves', 'same', 'ever', 'no', 'yourself', \"couldn't\", 'nine', 'had', 'hence', 'throughout', 'enough', \"didn't\", 'what',...l', \"you'll\", 'me', 'did', 'at', 'may', 'them', 'theirs', 'becoming', 'patient', 'should', \"don't\"}),\n",
       "        strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizer at 0x11931bbf8>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using idf\n",
    "# tfidf_vec = TfidfVectorizer(tokenizer = tokenizer, norm='l2', ngram_range=(1,3), max_df = 0.4,\n",
    "#                        stop_words = stop_words, use_idf=True)\n",
    "tfidf_vec = TfidfVectorizer(tokenizer = tokenizer, norm='l2', ngram_range=(1,4), sublinear_tf = True,\n",
    "                            stop_words = stop_words)\n",
    "tfidf_vec.fit(train_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:14.552925Z",
     "start_time": "2018-09-24T07:48:32.899185Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.transform(train_df['Abstract'].values)\n",
    "X_test_tfidf = tfidf_vec.transform(train_df['Abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:14.583771Z",
     "start_time": "2018-09-24T07:50:14.555265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1170755053673701\n",
      "0.0\n",
      "6.339074283646515e-06\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf[0].toarray().max())\n",
    "print(X_train_tfidf[0].toarray().min())\n",
    "print(X_train_tfidf[0].toarray().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:14.589615Z",
     "start_time": "2018-09-24T07:50:14.586171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2696733 features\n"
     ]
    }
   ],
   "source": [
    "print('There are %i features' % X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:14.594317Z",
     "start_time": "2018-09-24T07:50:14.591712Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = train_df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:14.601920Z",
     "start_time": "2018-09-24T07:50:14.596853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "- Use Chi Squared Test to select top k features\n",
    "    - Selects n_features with highest values for the test chi-squared statistic\n",
    "    - Chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n",
    "    - X^2 gives a measure of the distance between observed and expected frequencies.\n",
    "- Visualize the top N terms that are most correlated with each medical condition/disease using Chi squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:52:53.152792Z",
     "start_time": "2018-09-24T06:52:53.147887Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(train_df['Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:03:28.952704Z",
     "start_time": "2018-09-24T07:03:28.465185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi2(X_train_tfidf, train_df['Label'] == 1)[0][2644944]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:51:45.347986Z",
     "start_time": "2018-09-24T07:50:20.882620Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class #1:\n",
      "  Most correlated unigrams:\n",
      "     *carcinoma\n",
      "     *cancer\n",
      "     *tumor\n",
      "  Most correlated bigrams:\n",
      "     *squamou cell\n",
      "     *breast cancer\n",
      "     *cell carcinoma\n",
      "  Most correlated trigrams:\n",
      "     *basal cell carcinoma\n",
      "     *diseas free surviv\n",
      "     *squamou cell carcinoma\n",
      "  Most correlated four-grams:\n",
      "     *fine needl aspir biopsi\n",
      "     *non small cell lung\n",
      "     *small cell lung cancer\n",
      "Class #2:\n",
      "  Most correlated unigrams:\n",
      "     *cirrhosi\n",
      "     *gallston\n",
      "     *ulcer\n",
      "  Most correlated bigrams:\n",
      "     *ulcer coliti\n",
      "     *hepat b\n",
      "     *crohn diseas\n",
      "  Most correlated trigrams:\n",
      "     *primari biliari cirrhosi\n",
      "     *hepat b viru\n",
      "     *inflammatori bowel diseas\n",
      "  Most correlated four-grams:\n",
      "     *hepat b viru infect\n",
      "     *ulcer coliti crohn diseas\n",
      "     *hepat b viru dna\n",
      "Class #3:\n",
      "  Most correlated unigrams:\n",
      "     *cerebr\n",
      "     *brain\n",
      "     *seizur\n",
      "  Most correlated bigrams:\n",
      "     *cerebr palsi\n",
      "     *brain injuri\n",
      "     *parkinson diseas\n",
      "  Most correlated trigrams:\n",
      "     *carpal tunnel syndrom\n",
      "     *parkinson diseas pd\n",
      "     *magnet reson imag\n",
      "  Most correlated four-grams:\n",
      "     *carpal tunnel syndrom ct\n",
      "     *magnet reson imag mri\n",
      "     *gill la tourett syndrom\n",
      "Class #4:\n",
      "  Most correlated unigrams:\n",
      "     *myocardi\n",
      "     *hypertens\n",
      "     *coronari\n",
      "  Most correlated bigrams:\n",
      "     *left ventricular\n",
      "     *coronari arteri\n",
      "     *blood pressur\n",
      "  Most correlated trigrams:\n",
      "     *coronari heart diseas\n",
      "     *congest heart failur\n",
      "     *coronari arteri diseas\n",
      "  Most correlated four-grams:\n",
      "     *systol diastol blood pressur\n",
      "     *blood pressur mm hg\n",
      "     *angiotensin convert enzym inhibitor\n",
      "Class #5:\n",
      "  Most correlated unigrams:\n",
      "     *carcinoma\n",
      "     *cancer\n",
      "     *tumor\n",
      "  Most correlated bigrams:\n",
      "     *blood pressur\n",
      "     *respiratori tract\n",
      "     *tract infect\n",
      "  Most correlated trigrams:\n",
      "     *acut respiratori tract\n",
      "     *urinari tract infect\n",
      "     *respiratori tract infect\n",
      "  Most correlated four-grams:\n",
      "     *acut lower respiratori tract\n",
      "     *lower respiratori tract infect\n",
      "     *acut respiratori tract infect\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "for i in sorted(train_df['Label'].unique()):\n",
    "    features_chi2 = chi2(X_train_tfidf, train_df['Label'] == i)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf_vec.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "    fourgrams = [v for v in feature_names if len(v.split(' ')) == 4]\n",
    "    print(\"Class #%d:\" % i)\n",
    "    # Get last N values (np.argsort will return ascending values)\n",
    "    print(\"  Most correlated unigrams:\\n     *{}\".format('\\n     *'.join(unigrams[-N:])))\n",
    "    print(\"  Most correlated bigrams:\\n     *{}\".format('\\n     *'.join(bigrams[-N:])))\n",
    "    print(\"  Most correlated trigrams:\\n     *{}\".format('\\n     *'.join(trigrams[-N:])))\n",
    "    print(\"  Most correlated four-grams:\\n     *{}\".format('\\n     *'.join(fourgrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:32:23.817773Z",
     "start_time": "2018-09-24T06:32:19.150043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all the current feature names\n",
    "feature_names = tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:32:28.254714Z",
     "start_time": "2018-09-24T06:32:23.820269Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep_features = 1000000 \n",
    "keep_features = int(X_train_tfidf.shape[1] * 1.0)\n",
    "print('Keeping top %d features' % keep_features)\n",
    "chi_sq = SelectKBest(chi2, k = keep_features)\n",
    "X_train_tfidf = chi_sq.fit_transform(X_train_tfidf, Y_train)\n",
    "X_test_tfidf = chi_sq.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:32:29.346522Z",
     "start_time": "2018-09-24T06:32:28.257082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get new feature names\n",
    "feature_names = [feature_names[i] for i in chi_sq.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:32:29.355109Z",
     "start_time": "2018-09-24T06:32:29.349902Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-NN classifier\n",
    "\n",
    "- KNN is a lazy, nonparametric, instance based classifier \n",
    "- Let's first define some standard distance / similiarity metrics (We will use the sklearn implementation)\n",
    "    - Euclidean\n",
    "    - Jaccard\n",
    "        - Good when text is lemmatized and CountVectorizer is used\n",
    "        - Number of words that appear in a document are weighted the same and have no effect on this metric\n",
    "    - Cosine\n",
    "        - Good when using bag of words with tf-idf\n",
    "        - Have to normalize vectors when using cosine similarity\n",
    "    - Hamming distance\n",
    "        - Good for text classification\n",
    "    - Levenhstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:57:41.865805Z",
     "start_time": "2018-09-24T05:41:57.520Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distance Metrics.\n",
    "\n",
    "Compute the distance between two items (usually strings).\n",
    "As metrics, they must satisfy the following three requirements:\n",
    "\n",
    "1. d(a, a) = 0\n",
    "2. d(a, b) >= 0\n",
    "3. d(a, c) <= d(a, b) + d(b, c)\n",
    "\"\"\"\n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "def two_norm_sparse(x): \n",
    "    '''Calculates the two norm of a sparse matrix'''\n",
    "#     two_norm = np.sqrt(x.multiply(x).sum(1))\n",
    "    two_norm = np.sqrt(x.multiply(x).sum(1))\n",
    "#     print(two_norm)\n",
    "    return two_norm\n",
    "    \n",
    "\n",
    "def cosine_similarity_sparse(s1, s2):\n",
    "    '''Calculate cosine similiarity of two sparse matrices'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    numerator = s1.dot(s2.T)\n",
    "    return numerator\n",
    "\n",
    "\n",
    "def cosine_distance_sparse(s1, s2):\n",
    "    '''Calculate cosine distance of two sparse matrices (1 - cosine_similarity)'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    cos_sim = s1.dot(s2.T)\n",
    "    if s1.shape[0] > s2.shape[0]:\n",
    "        one_array = np.ones((s1.shape[0], 1), dtype=float)\n",
    "    else:\n",
    "        one_array = np.ones((s2.shape[0], 1), dtype=float)\n",
    "    return csr_matrix(one_array - cos_sim)\n",
    "\n",
    "def euclidean_distance_sparse(s1, s2):\n",
    "    '''Calcualte Euclidean distance of two sparse matrices'''\n",
    "    \n",
    "    i1 = s1.toarray()\n",
    "    i2 = s2.toarray()\n",
    "    d = csr_matrix(i1 - i2)\n",
    "    d = two_norm_sparse(d)\n",
    "#     d = np.sqrt(np.sum(np.power(i1 - i2, 2), axis=1, keepdims=True))\n",
    "    return csr_matrix(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:32.998739Z",
     "start_time": "2018-09-24T02:08:32.995809Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:33.265857Z",
     "start_time": "2018-09-24T02:08:33.263261Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:33.519264Z",
     "start_time": "2018-09-24T02:08:33.516364Z"
    }
   },
   "outputs": [],
   "source": [
    "# euclidean_distance_sparse(X_train_tfidf[0:30], X_train_tfidf[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:33.709725Z",
     "start_time": "2018-09-24T02:08:33.706135Z"
    }
   },
   "outputs": [],
   "source": [
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'euclidean')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'cosine')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'jaccard')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'hamming')\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'mahalanobis', VI=None)\n",
    "# cdist(X_train_tfidf[0:30].toarray(), X_train_tfidf[50].toarray(), 'chebyshev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:33.937155Z",
     "start_time": "2018-09-24T02:08:33.934363Z"
    }
   },
   "outputs": [],
   "source": [
    "# euclidean_distance_sparse(X_train_tfidf[0:30], X_train_tfidf[50]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:34.226103Z",
     "start_time": "2018-09-24T02:08:34.223122Z"
    }
   },
   "outputs": [],
   "source": [
    "# cosine_distance_sparse(X_train_tfidf[0:30], X_train_tfidf[50]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:34.595842Z",
     "start_time": "2018-09-24T02:08:34.538209Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_condition(train, labels, instance, K=5, metric = 'cosine'):\n",
    "    '''Using a distance metric to classify an instance'''\n",
    "    if metric == 'cosine':\n",
    "#         dots = cosine_similarity_sparse(instance, train)\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "#         reverse = True\n",
    "    elif metric == 'euclidean':\n",
    "        dots = euclidean_distance_sparse(train, instance)\n",
    "#         dots = csr_matrix(euclidean_distances(train.toarray(), instance.toarray()))\n",
    "#         dots = csr_matrix(cdist(train.toarray(), instance.toarray(), 'euclidean'))\n",
    "#         reverse = False\n",
    "    # Edit below later on\n",
    "    elif metric == 'jaccard':\n",
    "        dots = csr_matrix(cdist(train.toarray(), instance.toarray(), 'jaccard'))\n",
    "    else:\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "        \n",
    "        \n",
    "#     print(dots.indptr)\n",
    "    neighbors = list(zip(dots.indptr, dots.data))\n",
    "    if len(neighbors) == 0:\n",
    "        # could not find any neighbors\n",
    "        print('Could not find any neighbors.... Choosing a random one')\n",
    "        return np.asscalar(np.random.randint(low=1, high=5, size=1))\n",
    "#     neighbors.sort(key=lambda x: x[1], reverse=False)\n",
    "    neighbors.sort(key=lambda x: x[1], reverse=False)        \n",
    "        \n",
    "    tc = Counter(labels[s[0]] for s in neighbors[:K]).most_common(5)\n",
    "    if len(tc) < 5 or tc[0][1] > tc[1][1]:\n",
    "        # majority vote\n",
    "        return tc[0][0]\n",
    "    # tie break\n",
    "#     print('TIE BREAKER!!!!')\n",
    "    tc = defaultdict(float)\n",
    "     # Distance-Weighted Voting \n",
    "    for s in neighbors[:K]:\n",
    "        tc[labels[s[0]]] += (1 / (s[1]**2))\n",
    "#     for s in neighbors[:K]:\n",
    "#         tc[labels[s[0]]] += s[1]\n",
    "#     print(tc)\n",
    "    return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T02:08:35.196331Z",
     "start_time": "2018-09-24T02:08:35.176619Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(features, labels, fold_num = 1, fold=10):\n",
    "    n = features.shape[0]\n",
    "    fold_size = int(np.ceil(n*1.0/fold))\n",
    "    feats = []\n",
    "    cls_train = []\n",
    "    for f in range(fold):\n",
    "        if f+1 != fold_num:\n",
    "            feats.append(features[f*fold_size: min((f+1)*fold_size, n)])\n",
    "            cls_train.extend(labels[f*fold_size: min((f+1)*fold_size, n)])\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(feats, format='csr')\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "    test = features[(fold_num-1)*fold_size: min(fold_num*fold_size, n), :]\n",
    "    cls_test = labels[(fold_num-1)*fold_size: min(fold_num*fold_size, n)]\n",
    "    return train, cls_train, test, cls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T04:31:44.750789Z",
     "start_time": "2018-09-24T04:31:44.743115Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# x = [0, 0, 1, 5, 5, 0, 0, 3, 4, 1, 2]\n",
    "# y = [0, 0, 2, 5, 5, 0, 1, 3, 4, 4, 3]\n",
    "\n",
    "print(classification_report(x, y))\n",
    "print(f1_score(x, y, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:01:10.560492Z",
     "start_time": "2018-09-24T05:01:10.385271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics (Accuracy & F1 Score Functions)\n",
    "\n",
    "def calculate_accuracy(label, prediction):\n",
    "    '''Takes two numpy arrays or Python lists and produces an accuracy score in %'''\n",
    "    if isinstance(label, np.ndarray) and isinstance(prediction, np.ndarray):\n",
    "        assert label.shape == prediction.shape\n",
    "        return (label == prediction).all().mean() * 100.0\n",
    "    elif isinstance(label, list) and isinstance(prediction, list):\n",
    "        assert len(label) == len(prediction)\n",
    "        return sum(1 for a,b in zip(label, prediction) if a == b) / len(label)\n",
    "    else:\n",
    "        raise AttributeError('Both arguments have to be lists or numpy arrays')\n",
    "    \n",
    "def calculate_f1_score(label, prediction):\n",
    "    '''Takes two Python lists and produces an F1 score'''\n",
    "    label = set(label)\n",
    "    prediction = set(prediction)\n",
    "    # Calculate true positive, false positive & false negative\n",
    "    tp = len(label & prediction)\n",
    "    fp = len(prediction) - tp \n",
    "    fn = len(label) - tp\n",
    "\n",
    "    # Calculate precision & recall\n",
    "    precision=float(tp)/(tp+fp)\n",
    "    recall=float(tp)/(tp+fn)\n",
    "\n",
    "    # Return F1 Score\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "#     else:\n",
    "#         raise AttributeError('Both arguments have to be lists or numpy arrays')\n",
    "\n",
    "def calculate_weighted_f1_score(label, prediction):\n",
    "    if isinstance(label, np.ndarray) or isinstance(prediction, np.ndarray):\n",
    "        label = label.tolist()\n",
    "        prediction = prediction.tolist()\n",
    "        \n",
    "    f1_list = []\n",
    "    label_dict = Counter(label)\n",
    "    label_dict = sorted(label_dict.items(), key=lambda x: x[0])\n",
    "#     for l in set(label):\n",
    "    for l, support in label_dict:\n",
    "        tp = 0.\n",
    "        fp = 0.\n",
    "        tn = 0.\n",
    "        fn = 0.\n",
    "        for i in range(len(label)):\n",
    "            if prediction[i] == l:\n",
    "                if prediction[i] == label[i]:\n",
    "                    tp += 1.\n",
    "                else:\n",
    "                    fp += 1.\n",
    "            else:\n",
    "                if label[i] == l:\n",
    "                    fn += 1.\n",
    "#                 if prediction[i] == label[i]:\n",
    "#                     tn += 1.\n",
    "#                 else:\n",
    "#                     fn += 1.\n",
    "\n",
    "        # precision is \"how useful the search results are\"\n",
    "        precision = tp / (tp + fp)\n",
    "        # recall is \"how complete the results are\"\n",
    "        recall = tp / (tp + fn)\n",
    "        \n",
    "#         print('Precision: %.03f' % precision)\n",
    "#         print('Recall: %.03f' % recall)\n",
    "        if precision == 0.0 or recall == 0.0:\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        weighted_f1_score = f1_score * support\n",
    "#         print(f1_score)\n",
    "#         print(support)\n",
    "        f1_list.append(weighted_f1_score)\n",
    "#     print(f1_list)\n",
    "    return sum(f1_list) / len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:18:17.025771Z",
     "start_time": "2018-09-24T05:18:16.979855Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(features, labels, metric='cosine', K=3, fold=10):\n",
    "    '''Using KFold Cross Validation to evaluate model accuracy'''\n",
    "    \n",
    "    if metric not in ['cosine', 'euclidean', 'jaccard', 'hamming', 'mahalanobis']:\n",
    "        raise ValueError('Metric must be `cosine`, `euclidean`, or `jaccard`')\n",
    "    \n",
    "    macc = 0.0\n",
    "    cum_f1 = 0.0\n",
    "    for f in range(fold):\n",
    "        # split data into training and testing\n",
    "        train_set, train_labels, test_set, test_labels = split_data(features, labels, f+1, fold)\n",
    "        # predict the class of each test sample\n",
    "        predictions = np.array([classify_condition(train_set, train_labels, test_set[i,:], K=K, metric=metric) \n",
    "                       for i in range(test_set.shape[0])])\n",
    "        acc = calculate_accuracy(test_labels, predictions)\n",
    "#         f1 = calculate_weighted_f1_score(test_labels, predictions)\n",
    "        f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "#         print('Fold-%i Accuracy: %.05f' % (f+1, acc))\n",
    "        print('Fold-%i F1 Score: %.05f' % (f+1, f1))\n",
    "        macc += acc\n",
    "        cum_f1 += f1\n",
    "    \n",
    "    return macc/float(fold), cum_f1/float(fold)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:18:16.977502Z",
     "start_time": "2018-09-24T05:01:11.622295Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, f = evaluate_model(X_train_tfidf, Y_train, metric = 'cosine', K=69, fold=10)\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score 10-Fold CV Total Time Taken\n",
    "\n",
    "- My F1 score implementation (with Python lists): 17 minutes 5 seconds\n",
    "- Sklearn's F1 score implementation (with sparse matrices): 16 minutes 50 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out different distance metrics\n",
    "\n",
    "- Get same ordering as the cosine distance by normalizing your data and then using the euclidean distance.\n",
    "    - For **normalized vectors** cosine similarity and euclidean similarity are connected linearly.\n",
    "    - Sources [1](https://stats.stackexchange.com/questions/299013/cosine-distance-as-similarity-measure-in-kmeans) [2](https://stackoverflow.com/questions/34144632/using-cosine-distance-with-scikit-learn-kneighborsclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:20.869949Z",
     "start_time": "2018-09-24T07:50:14.604850Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "distance_metrics = ['chebyshev', 'manhattan', 'seuclidean', 'hamming']\n",
    "# distance_metrics_params = {'mahalanobis': np.cov(X_train_tfidf),\n",
    "#                           'seuclidean': np.cov(X_train_tfidf)}\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=69)\n",
    "\n",
    "scores = cross_val_score(knn, X_train_tfidf, Y_train, cv=10, scoring='f1_weighted', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:50:20.880915Z",
     "start_time": "2018-09-24T07:50:20.874065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60960191 0.5992119  0.63084952 0.6348669  0.60686858 0.60494872\n",
      " 0.61585073 0.6161558  0.62627984 0.60055894]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6145192832442493"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:28:03.686374Z",
     "start_time": "2018-09-24T07:27:05.794895Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "scores = cross_val_score(svm, X_train_tfidf, Y_train, cv=10, scoring='f1_weighted', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:28:03.695859Z",
     "start_time": "2018-09-24T07:28:03.689858Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:32:37.934308Z",
     "start_time": "2018-09-24T07:30:53.226728Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(LR, X_train_tfidf, Y_train, cv=10, scoring='f1_weighted', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:32:37.945624Z",
     "start_time": "2018-09-24T07:32:37.938906Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:32:52.599983Z",
     "start_time": "2018-09-24T07:32:48.273307Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "scores = cross_val_score(nb, X_train_tfidf, Y_train, cv=10, scoring='f1_weighted', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:32:54.303745Z",
     "start_time": "2018-09-24T07:32:54.296335Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline & then tune hyperparameter K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T21:36:16.862839Z",
     "start_time": "2018-09-22T21:36:08.927711Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=41)\n",
    "\n",
    "scores = cross_val_score(knn, X_train_tfidf, Y_train, cv=10, scoring='f1_weighted', n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T21:36:16.872016Z",
     "start_time": "2018-09-22T21:36:16.865957Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:51:45.358100Z",
     "start_time": "2018-09-24T07:51:45.350851Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "k_grid = np.arange(1, 100, 10)\n",
    "param_grid = {'n_neighbors': k_grid}\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10, scoring='f1_weighted', n_jobs=4, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:02:03.545382Z",
     "start_time": "2018-09-24T07:51:45.360233Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ......... n_neighbors=1, score=0.39929729219923016, total=   2.2s\n",
      "[CV] ......... n_neighbors=1, score=0.40560915427766703, total=   2.2s\n",
      "[CV] ......... n_neighbors=1, score=0.35894269809188006, total=   2.2s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ......... n_neighbors=1, score=0.42511103429048064, total=   1.8s\n",
      "[CV] .......... n_neighbors=1, score=0.3594224164491725, total=   1.8s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ........... n_neighbors=1, score=0.374295071386898, total=   1.8s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.3971040412764453, total=   1.7s\n",
      "[CV] ......... n_neighbors=1, score=0.38990599735330383, total=   1.6s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=1, score=0.39574365125932975, total=   1.6s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] .......... n_neighbors=1, score=0.3743671801887246, total=   1.6s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5714919343471964, total=   1.8s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5638087813365963, total=   1.7s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5811771951746798, total=   1.7s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5863668449393651, total=   1.8s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5850723401131628, total=   1.7s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5638284115918701, total=   1.7s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5694969182508006, total=   1.9s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5704934677060827, total=   1.8s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5901776114705268, total=   1.5s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=11, score=0.5737281503830712, total=   1.7s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5911087393801229, total=   1.6s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5973535645767871, total=   1.5s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.6102117731748345, total=   1.7s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.6116347288263841, total=   1.6s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.6017733851537546, total=   1.8s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.5964457020513413, total=   2.0s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ......... n_neighbors=21, score=0.6161592401814756, total=   1.9s\n",
      "[CV] n_neighbors=21 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=21, score=0.6002945779257771, total=   1.5s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] .......... n_neighbors=21, score=0.618437706209418, total=   1.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] .......... n_neighbors=21, score=0.601203090007627, total=   1.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6042700976654233, total=   1.6s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.5992474809012902, total=   1.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6202399709976139, total=   1.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6173788347409503, total=   1.6s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6073194467756575, total=   1.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.5958253476363938, total=   1.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6124386261859536, total=   1.5s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6034357778672244, total=   1.6s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] .......... n_neighbors=31, score=0.633283998890247, total=   1.6s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=31, score=0.6005275102416372, total=   1.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] .......... n_neighbors=41, score=0.600478832000235, total=   1.7s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6017256280749318, total=   1.6s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6351459429465146, total=   1.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ........... n_neighbors=41, score=0.61792472704748, total=   1.7s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6081284521015445, total=   1.7s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.5923548706939563, total=   1.7s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6245957820570106, total=   2.1s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6121134062071603, total=   1.9s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6331992681180976, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=41, score=0.6056040897774395, total=   1.7s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6018465562217546, total=   1.7s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6051543927757278, total=   1.9s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6382922256281142, total=   1.7s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.632844447896842, total=   1.7s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.617985573613614, total=   1.7s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.605020655349936, total=   2.1s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6221451612671872, total=   2.1s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6157163350724779, total=   2.0s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6267147527019234, total=   2.0s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6030200593484423, total=   2.0s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] .......... n_neighbors=61, score=0.609359405456147, total=   2.3s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6051764787362868, total=   1.8s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6306923042232854, total=   1.7s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6334825310472547, total=   2.2s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6117704007571289, total=   2.1s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6095186553313754, total=   2.1s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] .......... n_neighbors=61, score=0.615093719009647, total=   2.7s\n",
      "[CV] n_neighbors=61 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6128943585300061, total=   2.0s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.6311770088376252, total=   1.9s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=61, score=0.5984110260715799, total=   2.2s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6081226301269994, total=   2.0s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6083188056872821, total=   1.9s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6308244688915866, total=   2.1s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6282119680030628, total=   1.8s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6124840674924946, total=   1.8s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] .......... n_neighbors=71, score=0.607991090255807, total=   2.0s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6165604117865467, total=   1.8s\n",
      "[CV] n_neighbors=71 ..................................................\n",
      "[CV] .......... n_neighbors=71, score=0.613437316899286, total=   1.7s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6279124199834538, total=   2.0s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=71, score=0.6081364089380433, total=   1.8s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6145222207371854, total=   1.8s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6072554506363147, total=   1.9s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6351708650529007, total=   1.8s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ........... n_neighbors=81, score=0.63205374169151, total=   1.7s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6050518457501204, total=   2.0s\n",
      "[CV] n_neighbors=81 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=81, score=0.6056133417852848, total=   1.8s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6175400903192604, total=   1.7s\n",
      "[CV] n_neighbors=81 ..................................................\n",
      "[CV] .......... n_neighbors=81, score=0.611054254450855, total=   1.9s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6209330069569936, total=   1.7s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=81, score=0.6030284050835907, total=   1.7s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6144437224815352, total=   1.7s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6022796724549465, total=   2.1s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] .......... n_neighbors=91, score=0.629679861578237, total=   2.1s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6238220620972906, total=   1.8s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6028220087785666, total=   2.0s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6022277846300346, total=   2.1s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6207668380369828, total=   1.7s\n",
      "[CV] n_neighbors=91 ..................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6127180644714114, total=   1.9s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ......... n_neighbors=91, score=0.6224397991058765, total=   1.8s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ......... n_neighbors=91, score=0.5954674177664391, total=   2.0s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6075477286912799, total=   1.7s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ......... n_neighbors=101, score=0.599662968622672, total=   1.7s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ......... n_neighbors=101, score=0.626055822399466, total=   1.8s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6187984005795261, total=   1.8s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6047803845210539, total=   1.7s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6028345417705618, total=   1.7s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6141302241233783, total=   1.8s\n",
      "[CV] n_neighbors=101 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6025478671571215, total=   1.7s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.6298503595272731, total=   1.8s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=101, score=0.5989550599307977, total=   1.8s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6076887174149308, total=   1.7s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6010807437689676, total=   1.7s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6240064977155865, total=   1.9s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6186835325184197, total=   1.8s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.5988705450609579, total=   1.7s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ......... n_neighbors=111, score=0.611599846785965, total=   1.8s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6125772636774789, total=   1.7s\n",
      "[CV] n_neighbors=111 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6063732406785888, total=   1.7s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6298086857589684, total=   1.8s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=111, score=0.6004843846856818, total=   1.8s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6073893514724958, total=   1.8s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5953156174410619, total=   1.7s\n",
      "[CV] n_neighbors=121 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  9.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ n_neighbors=121, score=0.6285985824580712, total=   1.7s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ......... n_neighbors=121, score=0.619487471633984, total=   1.7s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6007003563022757, total=   1.9s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6106300799830087, total=   1.8s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ......... n_neighbors=121, score=0.610858188778574, total=   1.7s\n",
      "[CV] n_neighbors=121 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6020608992296167, total=   1.9s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.6277534469764947, total=   1.8s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=121, score=0.5974371819035121, total=   1.7s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] .......... n_neighbors=131, score=0.60129019046827, total=   1.9s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.5934007283472104, total=   1.8s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6246203824974529, total=   2.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6136652580010762, total=   2.2s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6048251487741737, total=   2.1s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6015128599445084, total=   1.6s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6162118698142534, total=   1.7s\n",
      "[CV] n_neighbors=131 .................................................\n",
      "[CV] ........ n_neighbors=131, score=0.6002677348656047, total=   1.7s\n",
      "[CV] ........ n_neighbors=131, score=0.6267197003855772, total=   1.6s\n",
      "[CV] ........ n_neighbors=131, score=0.5964926036290416, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 140 out of 140 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'n_neighbors': array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:02:03.557130Z",
     "start_time": "2018-09-24T08:02:03.550096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 51}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:02:03.564935Z",
     "start_time": "2018-09-24T08:02:03.559658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6168749712070135"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:02:48.415828Z",
     "start_time": "2018-09-24T08:02:48.404677Z"
    }
   },
   "outputs": [],
   "source": [
    "k_grid = np.arange(42, 61, 1)\n",
    "param_grid = {'n_neighbors': k_grid}\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10, scoring='f1_weighted', n_jobs=4, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:16:13.928775Z",
     "start_time": "2018-09-24T08:02:48.696607Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6039956386024407, total=   1.9s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] .......... n_neighbors=42, score=0.600556585031218, total=   1.9s\n",
      "[CV] ......... n_neighbors=42, score=0.6354097775612313, total=   1.9s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6211944811805191, total=   1.8s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6126482298316405, total=   1.8s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.5969634929844924, total=   1.8s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6220875199235456, total=   2.0s\n",
      "[CV] n_neighbors=42 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6150615149772078, total=   1.9s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6320756918281654, total=   1.9s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=42, score=0.6096197494634017, total=   2.2s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6018115004620674, total=   2.2s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6050502891371227, total=   2.2s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6302251729890227, total=   2.2s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6146051400191213, total=   2.2s\n",
      "[CV] ......... n_neighbors=43, score=0.6144771091216671, total=   2.3s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.5999718922091956, total=   1.9s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6160310780633046, total=   1.8s\n",
      "[CV] n_neighbors=43 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6237543541151535, total=   1.8s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] .......... n_neighbors=43, score=0.630395512638429, total=   1.9s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=43, score=0.6036336692548951, total=   1.9s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6005904798207087, total=   1.8s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6028975370024099, total=   2.0s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] .......... n_neighbors=44, score=0.636845748862886, total=   2.0s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6185795548409218, total=   2.0s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6119812446552265, total=   1.9s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6001110969633418, total=   1.8s\n",
      "[CV] n_neighbors=44 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6238940176647201, total=   1.8s\n",
      "[CV] n_neighbors=44 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=44, score=0.6209499176442981, total=   1.8s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=44, score=0.6240399462568287, total=   1.8s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] .......... n_neighbors=44, score=0.606542463153329, total=   1.8s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.5989205675863764, total=   1.8s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6033118913694928, total=   1.8s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6305148810971721, total=   1.7s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6195136222538212, total=   1.7s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6132914328231815, total=   1.8s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6035336815474791, total=   1.7s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6230156471714143, total=   1.9s\n",
      "[CV] n_neighbors=45 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6194336455424211, total=   2.0s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.6308030530916563, total=   2.1s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=45, score=0.5997992774362897, total=   1.7s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6073181969937221, total=   1.8s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6053528199601584, total=   1.7s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6350678318722218, total=   1.8s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6221425987414659, total=   1.8s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6147014424143176, total=   1.7s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6046740594829524, total=   1.7s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6208436262032044, total=   1.7s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6215643585109878, total=   1.7s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6300458115546761, total=   1.7s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=46, score=0.6062356080692132, total=   1.7s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6035536882945638, total=   1.7s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6042367389101847, total=   1.7s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6338725091537175, total=   1.8s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6260209621683441, total=   1.7s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6116108194458885, total=   1.9s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6042016719967184, total=   2.0s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6252099096851796, total=   1.9s\n",
      "[CV] n_neighbors=47 ..................................................\n",
      "[CV] .......... n_neighbors=47, score=0.616914425090749, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6292064813320453, total=   1.7s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=47, score=0.6026004115621274, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6016647040520509, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6093810822341628, total=   1.7s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6360329527094646, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6204656137577533, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6154716052642694, total=   1.7s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6038292991317531, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6229591021732562, total=   1.6s\n",
      "[CV] n_neighbors=48 ..................................................\n",
      "[CV] ........... n_neighbors=48, score=0.61612346831913, total=   1.7s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6280855769821809, total=   1.6s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=48, score=0.6041132140582994, total=   1.6s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6033988682642926, total=   1.7s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ........... n_neighbors=49, score=0.60842478483062, total=   1.6s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6351802050159809, total=   1.6s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6327227149729504, total=   1.7s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] .......... n_neighbors=49, score=0.615104160365381, total=   1.6s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] .......... n_neighbors=49, score=0.604627660985448, total=   1.5s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6184050677260973, total=   1.7s\n",
      "[CV] n_neighbors=49 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6182475842236039, total=   1.6s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=49, score=0.6280022382493483, total=   1.5s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] .......... n_neighbors=49, score=0.604435541051591, total=   1.7s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6015124861095403, total=   1.6s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6080312440074359, total=   1.5s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6351409874253434, total=   1.7s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6301572614943683, total=   1.6s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6177659650113186, total=   1.8s\n",
      "[CV] n_neighbors=50 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=50, score=0.6105239585073757, total=   2.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6152941460132143, total=   2.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6139777873247112, total=   1.5s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6308086384731811, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.6053661145110183, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6018465562217546, total=   1.5s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6051543927757278, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6382922256281142, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.632844447896842, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.617985573613614, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] .......... n_neighbors=51, score=0.605020655349936, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6221451612671872, total=   1.6s\n",
      "[CV] n_neighbors=51 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6157163350724779, total=   1.7s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6267147527019234, total=   1.6s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=51, score=0.6030200593484423, total=   1.6s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6038869943319743, total=   1.6s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6009869688850558, total=   1.8s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6332677097690762, total=   1.8s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ............ n_neighbors=52, score=0.6341333583733, total=   1.9s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6131097425165546, total=   1.7s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] .......... n_neighbors=52, score=0.612555077276527, total=   2.1s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6245498273882595, total=   1.9s\n",
      "[CV] n_neighbors=52 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6165030066816184, total=   1.8s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6262698746378904, total=   1.9s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=52, score=0.6015910530125899, total=   1.8s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] .......... n_neighbors=53, score=0.603250727827962, total=   1.7s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6023108150058591, total=   2.0s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6388782343912721, total=   1.9s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6307692451202914, total=   1.7s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6135045629695898, total=   1.6s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6105623982235003, total=   1.6s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6216332817176399, total=   1.6s\n",
      "[CV] n_neighbors=53 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6152055336902701, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=53, score=0.6290565622769473, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] .......... n_neighbors=53, score=0.602693069202222, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6066623320383403, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6029824645691161, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  8.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=54, score=0.6408533091497388, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6385244563115771, total=   1.7s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6159869740920709, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6099181189646462, total=   1.6s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6229285975221526, total=   1.7s\n",
      "[CV] n_neighbors=54 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6146927988502036, total=   1.7s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=54, score=0.6264764419455768, total=   1.7s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] .......... n_neighbors=54, score=0.602148354393289, total=   1.9s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6091592091698379, total=   1.7s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] .......... n_neighbors=55, score=0.604007258092505, total=   1.6s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6398943240555435, total=   1.8s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6322271736819557, total=   1.6s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6099667142997071, total=   1.8s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] .......... n_neighbors=55, score=0.612203694683306, total=   1.8s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6200371098241428, total=   1.7s\n",
      "[CV] n_neighbors=55 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6148123803634311, total=   1.7s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.6257470274555712, total=   2.2s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=55, score=0.5999499443026574, total=   1.7s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6081253610218414, total=   1.9s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6027148252077398, total=   1.8s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6392873284157713, total=   1.6s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6356454119747276, total=   1.6s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6071011813697118, total=   2.2s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6077101947550179, total=   1.8s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] .......... n_neighbors=56, score=0.618628159844331, total=   1.6s\n",
      "[CV] n_neighbors=56 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6145190766719862, total=   1.8s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=56, score=0.6264832047852441, total=   1.6s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] .......... n_neighbors=56, score=0.598612478572457, total=   1.6s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6063737579963688, total=   1.8s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6034286603777372, total=   1.6s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6392789187743235, total=   1.6s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6306430706335877, total=   1.8s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6093009274162976, total=   1.6s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6089959917134057, total=   1.6s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] .......... n_neighbors=57, score=0.619217671378846, total=   1.9s\n",
      "[CV] n_neighbors=57 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6158832382230817, total=   1.7s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6276852779395258, total=   1.7s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=57, score=0.6010989714786844, total=   1.8s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6069249211951765, total=   1.6s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6030998337381862, total=   1.6s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6352517121889927, total=   2.1s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6324262874446344, total=   2.0s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6103691878050627, total=   1.9s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6090745396453525, total=   1.8s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6213601858189058, total=   1.6s\n",
      "[CV] n_neighbors=58 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6121363881963808, total=   1.6s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6268012506471236, total=   1.9s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=58, score=0.6005654532270914, total=   1.7s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6087199969229093, total=   1.6s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6044954544031097, total=   1.9s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6397657064801417, total=   1.8s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6364208352861019, total=   2.1s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6080418894810697, total=   1.9s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6111096348642209, total=   1.7s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6232617019466881, total=   1.6s\n",
      "[CV] n_neighbors=59 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6111334885503896, total=   1.7s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.6349956103274648, total=   1.6s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=59, score=0.5955654650286004, total=   1.6s\n",
      "[CV] n_neighbors=60 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=60, score=0.6098267480717249, total=   1.7s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6054303192684253, total=   1.6s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6354045920286664, total=   1.6s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6380391861735909, total=   1.9s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6097268880184853, total=   1.6s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6108608489057045, total=   1.9s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6189819228216769, total=   1.7s\n",
      "[CV] n_neighbors=60 ..................................................\n",
      "[CV] ......... n_neighbors=60, score=0.6149841786838605, total=   1.6s\n",
      "[CV] ......... n_neighbors=60, score=0.6329383515087248, total=   1.6s\n",
      "[CV] ......... n_neighbors=60, score=0.6016482576876514, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 190 out of 190 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'n_neighbors': array([42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
       "       59, 60])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:16:13.935111Z",
     "start_time": "2018-09-24T08:16:13.931326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 54}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:16:13.940477Z",
     "start_time": "2018-09-24T08:16:13.937010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6181194688081953"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:53:12.626276Z",
     "start_time": "2018-09-22T03:48:10.373Z"
    }
   },
   "outputs": [],
   "source": [
    "best_f1 = 0.0\n",
    "best_k = None\n",
    "best_acc = 0.0\n",
    "\n",
    "# sqrt(# of training records) ~ 140  \n",
    "for k in np.arange(1, 140, 5):\n",
    "    acc, f1 = evaluate_model(X_train_tfidf, Y_train, K=k, fold=10)\n",
    "#     print('For %i-NN, 10-Fold CV Average Accuracy: %.05f%%' % (k, acc * 100.0)) \n",
    "    print('For %i-NN, 10-Fold CV Weighted F1 Score: %.05f' % (k, f1)) \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_acc = acc\n",
    "        best_k = k\n",
    "    \n",
    "print('Best Model Params: \\n For %i-NN, 10-Fold CV Weighted F1 Score: %.08f' (best_k, best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
