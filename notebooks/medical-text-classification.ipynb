{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR1: Medical Text Classification\n",
    "\n",
    "* Author: Kevin Chuang [@k-chuang](https://www.github.com/k-chuang)\n",
    "* Created on: September 21, 2018\n",
    "* Description: Given a medical abstract, classify condition of patient (5 classes) using K-Nearest Neighbors.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:25.764274Z",
     "start_time": "2018-10-01T01:09:24.513082Z"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Text Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilities\n",
    "import string\n",
    "import math\n",
    "from operator import itemgetter \n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20.0, 10.0), \"axes.labelsize\": 14})\n",
    "\n",
    "# sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.217325Z",
     "start_time": "2018-10-01T01:09:25.766881Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../train.dat', sep='\\t', header=None, names=['Label', 'Abstract'])\n",
    "test_df = pd.read_csv('../test.dat', sep='\\t', header=None, names=['Abstract'])\n",
    "submission_df = pd.read_csv('../format.dat', header=None, names=['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.232261Z",
     "start_time": "2018-10-01T01:09:26.219584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Catheterization laboratory events and hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Renal abscess in children. Three cases of rena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hyperplastic polyps seen at sigmoidoscopy are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Subclavian artery to innominate vein fistula a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Effect of local inhibition of gamma-aminobutyr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Abstract\n",
       "0      4  Catheterization laboratory events and hospital...\n",
       "1      5  Renal abscess in children. Three cases of rena...\n",
       "2      2  Hyperplastic polyps seen at sigmoidoscopy are ...\n",
       "3      5  Subclavian artery to innominate vein fistula a...\n",
       "4      4  Effect of local inhibition of gamma-aminobutyr..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.242842Z",
     "start_time": "2018-10-01T01:09:26.234480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excision of limbal dermoids. We reviewed the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bell's palsy. A diagnosis of exclusion. In cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retained endobronchial foreign body removal fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recurrent buccal space abscesses: a complicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intracranial fibromatosis. Fibromatoses are un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract\n",
       "0  Excision of limbal dermoids. We reviewed the c...\n",
       "1  Bell's palsy. A diagnosis of exclusion. In cas...\n",
       "2  Retained endobronchial foreign body removal fa...\n",
       "3  Recurrent buccal space abscesses: a complicati...\n",
       "4  Intracranial fibromatosis. Fibromatoses are un..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.249817Z",
     "start_time": "2018-10-01T01:09:26.245159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine train and test abstracts to use for building vectorizer\n",
    "abstract_df = pd.concat([train_df['Abstract'], test_df['Abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.256259Z",
     "start_time": "2018-10-01T01:09:26.252092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28880,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "- See other notebook for detailed EDA \n",
    "    - [exploratory-data-analysis.ipynb]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Going to use `Bag of Words` approach\n",
    "    - presence of words (frequency or count) is taken into consideration & order is ignored\n",
    "    - BOW basically breaks up the note into the individual words and counts how many times each word occurs.\n",
    "- Tokenizer and a vectorizer. \n",
    "    - The tokenizer breaks a single abstract into a list of words and a vectorizer takes a list of words and counts the words.\n",
    "- `Tokenizer`:\n",
    "    - Remove punctuation & numbers\n",
    "    - Lowercase everything\n",
    "    - Two approaches for tokenization\n",
    "        - Goal is reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "        - `WordNetLemmatizer`\n",
    "            - Lemmatize all the text (e.g. women will become woman)\n",
    "                - Lemmatization is the process of converting the words of a sentence to its dictionary form. \n",
    "        - `PorterStemmer`\n",
    "            - Stem all the text\n",
    "                - Stemming is the process of converting words to the stem (root) of the word\n",
    "- `Vectorizer`:\n",
    "    - General process of turning a collection of text documents into numerical feature vectors. \n",
    "    - This specific strategy (tokenization, counting and normalization) is called the Bag of Words or “Bag of n-grams” representation. \n",
    "    - Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "    - `CountVectorizer`\n",
    "        - Encodes a vector with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "        - `vocabulary_` is a dict/mapping of the terms to their indices in the document-term matrix, not the counts.\n",
    "    - `TfidfVectorizer`\n",
    "        - Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "            - Normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents.\n",
    "        - TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "            - *This can be extremely useful for this problem, since we have 5 categories we are trying to classify and thus certain categories (medical conditions) may have words in the medical abstract that are unique to the condition*\n",
    "        - The resulting tf-idf vectors are then normalized by the Euclidean norm (L2)\n",
    "        - **Since the medical text data have a lot of multi-word expressions (e.g. *left anterior descending coronary artery*), I will use N-grams (where N >= 1) to keep the local positioning of these important words **\n",
    "            - Experimented with N-grams, and it seems 1-gram, 2-gram, 3-gram, and 4-grams produce best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.333680Z",
     "start_time": "2018-10-01T01:09:26.258758Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemma_tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    # Use Lemma tokenizer to tokenize the words\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lemmas = [lemma.lemmatize(word.strip()) for word in text.split()]\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "def word_tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    # Best Stemmer for this dataset (Tested)\n",
    "    stemmer = PorterStemmer()\n",
    "#     stemmer = SnowballStemmer(\"english\")\n",
    "#     stemmer = LancasterStemmer()\n",
    "    stems = [stemmer.stem(word.strip()) for word in text.split()]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.565007Z",
     "start_time": "2018-10-01T01:09:26.557633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create stop words list & remove unimportant words such as 'the' or 'and'\n",
    "\n",
    "# 153 stop words from NLTK\n",
    "nltk_stop_words = stopwords.words('english')\n",
    "# Combine stop words from all the stop word lists\n",
    "stop_words = ENGLISH_STOP_WORDS.union(nltk_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:09:26.969856Z",
     "start_time": "2018-10-01T01:09:26.965083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 381 stop words\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:11:56.096520Z",
     "start_time": "2018-10-01T01:09:27.783440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 5), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset({'made', 'even', 'sometime', 've', 'do', 'won', 'she', 'these', 'empty', 'others', 'every', 'anyone', 'became', 'nothing', 'already', 'rather', 'much', 'other', \"hasn't\", 'formerly', 'sometimes', 'amoungst', 'whole', 'at', 'keep', 'mill', 'are', 'everyone', 'both', 'around', 'fe...that'll\", 'hereupon', 'sincere', 'seems', 'go', 'who', 'during', 'toward', 'himself', 'back', 'as'}),\n",
       "        strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizer at 0x105dcaea0>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using tf-idf\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(tokenizer = tokenizer, norm='l2', ngram_range=(1,2), sublinear_tf = True, min_df = 5,\n",
    "                            stop_words = stop_words)\n",
    "tfidf_vec.fit(abstract_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.058177Z",
     "start_time": "2018-10-01T01:11:56.098737Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.transform(train_df['Abstract'].values)\n",
    "X_test_tfidf = tfidf_vec.transform(test_df['Abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.063182Z",
     "start_time": "2018-10-01T01:13:42.059896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 139118 features\n"
     ]
    }
   ],
   "source": [
    "print('There are %i features' % X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.071781Z",
     "start_time": "2018-10-01T01:13:42.065078Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = train_df['Label'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-NN classifier\n",
    "\n",
    "- KNN is a lazy, nonparametric, instance based classifier \n",
    "- Using cosine distance as the distance metric for kNN\n",
    "    - Good when using bag of words with tf-idf\n",
    "    - Have to normalize vectors when using cosine similarity (which `TfidfVectorizer` does already with L2 normalization)\n",
    "- Uses majority voting of K nearest neighbors to determine the label of an instance\n",
    "- If there is a stalemate, I use the instances of the labels that tied, and calculate their inverse distance squared to determine the final winner\n",
    "    - A higher inverse squared distance score correlates with a higher similarity (farther distance squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.086830Z",
     "start_time": "2018-10-01T01:13:42.074418Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distance Metrics.\n",
    "\n",
    "Compute the distance between two items (usually strings).\n",
    "As metrics, they must satisfy the following three requirements:\n",
    "\n",
    "1. d(a, a) = 0\n",
    "2. d(a, b) >= 0\n",
    "3. d(a, c) <= d(a, b) + d(b, c)\n",
    "\"\"\"\n",
    "    \n",
    "def cosine_similarity_sparse(s1, s2):\n",
    "    '''Calculate cosine similiarity of two sparse matrices'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    numerator = s1.dot(s2.T)\n",
    "    return numerator\n",
    "\n",
    "def cosine_distance_sparse(s1, s2):\n",
    "    '''Calculate cosine distance of two sparse matrices (1 - cosine_similarity)'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    cos_sim = s1.dot(s2.T)\n",
    "    if s1.shape[0] > s2.shape[0]:\n",
    "        one_array = np.ones((s1.shape[0], 1), dtype=float)\n",
    "    else:\n",
    "        one_array = np.ones((s2.shape[0], 1), dtype=float)\n",
    "    return csr_matrix(one_array - cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.105820Z",
     "start_time": "2018-10-01T01:13:42.088871Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(features, labels, fold_num = 1, fold=10):\n",
    "    n = features.shape[0]\n",
    "    fold_size = int(np.ceil(n*1.0/fold))\n",
    "    feats = []\n",
    "    cls_train = []\n",
    "    for f in range(fold):\n",
    "        if f+1 != fold_num:\n",
    "            feats.append(features[f*fold_size: min((f+1)*fold_size, n)])\n",
    "            cls_train.extend(labels[f*fold_size: min((f+1)*fold_size, n)])\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(feats, format='csr')\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "    test = features[(fold_num-1)*fold_size: min(fold_num*fold_size, n), :]\n",
    "    cls_test = labels[(fold_num-1)*fold_size: min(fold_num*fold_size, n)]\n",
    "    return train, cls_train, test, cls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.220180Z",
     "start_time": "2018-10-01T01:13:42.108968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics (Accuracy & F1 Score Functions)\n",
    "\n",
    "def calculate_accuracy(label, prediction):\n",
    "    '''Takes two numpy arrays or Python lists and produces an accuracy score in %'''\n",
    "    if isinstance(label, np.ndarray) and isinstance(prediction, np.ndarray):\n",
    "        assert label.shape == prediction.shape\n",
    "        return (label == prediction).all().mean() * 100.0\n",
    "    elif isinstance(label, list) and isinstance(prediction, list):\n",
    "        assert len(label) == len(prediction)\n",
    "        return sum(1 for a,b in zip(label, prediction) if a == b) / len(label)\n",
    "    else:\n",
    "        raise AttributeError('Both arguments have to be lists or numpy arrays')\n",
    "\n",
    "def calculate_weighted_f1_score(label, prediction):\n",
    "    if isinstance(label, np.ndarray) or isinstance(prediction, np.ndarray):\n",
    "        label = label.tolist()\n",
    "        prediction = prediction.tolist()\n",
    "    f1_list = []\n",
    "    label_dict = Counter(label)\n",
    "    label_dict = sorted(label_dict.items(), key=lambda x: x[0])\n",
    "    for l, support in label_dict:\n",
    "        tp = 0.\n",
    "        fp = 0.\n",
    "        tn = 0.\n",
    "        fn = 0.\n",
    "        for i in range(len(label)):\n",
    "            if prediction[i] == l:\n",
    "                if prediction[i] == label[i]:\n",
    "                    tp += 1.\n",
    "                else:\n",
    "                    fp += 1.\n",
    "            else:\n",
    "                if label[i] == l:\n",
    "                    fn += 1.\n",
    "        # precision is \"how useful the search results are\"\n",
    "        precision = tp / (tp + fp)\n",
    "        # recall is \"how complete the results are\"\n",
    "        recall = tp / (tp + fn)\n",
    "        \n",
    "        if precision == 0.0 or recall == 0.0:\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        weighted_f1_score = f1_score * support\n",
    "        f1_list.append(weighted_f1_score)\n",
    "    return sum(f1_list) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.299903Z",
     "start_time": "2018-10-01T01:13:42.222198Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_condition(train, labels, instance, K=5, metric = 'cosine'):\n",
    "    '''Using a distance metric to classify an instance'''\n",
    "    if metric == 'cosine':\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "    elif metric == 'euclidean':\n",
    "        dots = euclidean_distance_sparse(train, instance)\n",
    "    # Edit below later on\n",
    "    elif metric == 'jaccard':\n",
    "        dots = csr_matrix(cdist(train.toarray(), instance.toarray(), 'jaccard'))\n",
    "    else:\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "        \n",
    "        \n",
    "    neighbors = list(zip(dots.indptr, dots.data))\n",
    "    if len(neighbors) == 0:\n",
    "        # could not find any neighbors\n",
    "        print('Could not find any neighbors.... Choosing a random one')\n",
    "        return np.asscalar(np.random.randint(low=1, high=5, size=1))\n",
    "    neighbors.sort(key=lambda x: x[1], reverse=False)        \n",
    "        \n",
    "    tc = Counter(labels[s[0]] for s in neighbors[:K]).most_common(5)\n",
    "    \n",
    "    if len(tc) == 1 or tc[0][1] > tc[1][1]:\n",
    "        # majority vote\n",
    "        return tc[0][0]\n",
    "\n",
    "    # tie break\n",
    "    # Only keep tied labels\n",
    "    num_n = tc[0][1]\n",
    "    keep_labels = [l for l, c in tc if c == num_n]\n",
    "    tc = defaultdict(float)\n",
    "     # Distance-Weighted Voting \n",
    "    for s in neighbors[:K]:\n",
    "        if labels[s[0]] not in keep_labels:\n",
    "            continue\n",
    "        else:\n",
    "            tc[labels[s[0]]] += (1 / (s[1]**2))\n",
    "            \n",
    "    return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T01:13:42.338053Z",
     "start_time": "2018-10-01T01:13:42.302438Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(features, labels, metric='cosine', K=3, fold=10):\n",
    "    '''Using KFold Cross Validation to evaluate model accuracy'''\n",
    "    \n",
    "    if metric not in ['cosine', 'euclidean', 'jaccard', 'hamming', 'mahalanobis']:\n",
    "        raise ValueError('Metric must be `cosine`, `euclidean`, or `jaccard`')\n",
    "    \n",
    "    macc = 0.0\n",
    "    cum_f1 = 0.0\n",
    "    for f in range(fold):\n",
    "        # split data into training and testing\n",
    "        train_set, train_labels, test_set, test_labels = split_data(features, labels, f+1, fold)\n",
    "        # predict the class of each test sample\n",
    "        predictions = np.array([classify_condition(train_set, train_labels, test_set[i,:], K=K, metric=metric) \n",
    "                       for i in range(test_set.shape[0])])\n",
    "        acc = calculate_accuracy(test_labels, predictions)\n",
    "#         f1 = calculate_weighted_f1_score(test_labels, predictions)\n",
    "        f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "#         print('Fold-%i Accuracy: %.05f' % (f+1, acc))\n",
    "        print('Fold-%i F1 Score: %.05f' % (f+1, f1))\n",
    "        macc += acc\n",
    "        cum_f1 += f1\n",
    "    \n",
    "    return macc/float(fold), cum_f1/float(fold)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score 10-Fold CV Total Time Taken\n",
    "\n",
    "- My F1 score implementation (with Python lists): 17 minutes 5 seconds\n",
    "- Sklearn's F1 score implementation (with sparse matrices): 16 minutes 50 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameter K\n",
    "\n",
    "- Implementation of simple grid search through various values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:10:37.254024Z",
     "start_time": "2018-10-01T05:10:37.232552Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(features, labels, start, end, inc=1):\n",
    "    '''My Grid Search Function'''\n",
    "    best_f1 = 0.0\n",
    "    best_k = 0\n",
    "    best_acc = 0.0\n",
    "    for k in np.arange(start, end, inc):\n",
    "        acc, f1 = evaluate_model(features, labels, K=k, fold=10)\n",
    "#         print('For %i-NN, 10-Fold CV Average Accuracy: %.05f%%' % (k, acc * 100.0)) \n",
    "        print('For %i-NN, 10-Fold CV Weighted F1 Score: %.05f' % (k, f1)) \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_acc = acc\n",
    "            best_k = k\n",
    "    \n",
    "    print('Best Model Params: \\n For %d-NN, 10-Fold CV Weighted F1 Score: %.08f'% (best_k, best_f1))\n",
    "    return best_k, best_acc, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:11:09.974730Z",
     "start_time": "2018-10-01T05:10:39.037946Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1 F1 Score: 0.58120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fb8c7a7afb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-85136de036b5>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(features, labels, start, end, inc)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print('For %i-NN, 10-Fold CV Average Accuracy: %.05f%%' % (k, acc * 100.0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For %i-NN, 10-Fold CV Weighted F1 Score: %.05f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6d8fd91bf52d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(features, labels, metric, K, fold)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# predict the class of each test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         predictions = np.array([classify_condition(train_set, train_labels, test_set[i,:], K=K, metric=metric) \n\u001b[0;32m---> 14\u001b[0;31m                        for i in range(test_set.shape[0])])\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         f1 = calculate_weighted_f1_score(test_labels, predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6d8fd91bf52d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# predict the class of each test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         predictions = np.array([classify_condition(train_set, train_labels, test_set[i,:], K=K, metric=metric) \n\u001b[0;32m---> 14\u001b[0;31m                        for i in range(test_set.shape[0])])\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         f1 = calculate_weighted_f1_score(test_labels, predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d0cadd878611>\u001b[0m in \u001b[0;36mclassify_condition\u001b[0;34m(train, labels, instance, K, metric)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# could not find any neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K, acc, f1 = grid_search(X_train_tfidf, Y_train, start=10, end=80, inc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K, acc, f1 = grid_search(X_train_tfidf, Y_train, start=30, end=60, inc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T02:51:15.012304Z",
     "start_time": "2018-09-25T02:51:15.006643Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_condition(X_train, Y_train, X_test, K = 69):\n",
    "    predictions = np.array([classify_condition(X_train, Y_train, X_test[i,:], K=K, metric='cosine') \n",
    "                       for i in range(X_test.shape[0])])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:11:33.201213Z",
     "start_time": "2018-09-25T02:51:15.323570Z"
    }
   },
   "outputs": [],
   "source": [
    "final_predictions = predict_condition(X_train_tfidf, Y_train, X_test_tfidf, K = K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:20:05.283789Z",
     "start_time": "2018-09-25T03:20:05.210919Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df['Labels'] = final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:21:42.972143Z",
     "start_time": "2018-09-25T03:21:42.940940Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.txt', sep='\\n', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
