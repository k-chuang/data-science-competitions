{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR1: Medical Text Classification\n",
    "\n",
    "* Author: Kevin Chuang [@k-chuang](https://www.github.com/k-chuang)\n",
    "* Created on: September 21, 2018\n",
    "* Description: Given a medical abstract, classify condition of patient (5 classes) using K-Nearest Neighbors.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.211327Z",
     "start_time": "2018-10-01T05:19:12.190194Z"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Text Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# Utilities\n",
    "import string\n",
    "import math\n",
    "from operator import itemgetter \n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20.0, 10.0), \"axes.labelsize\": 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.595565Z",
     "start_time": "2018-10-01T05:19:13.213833Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../train.dat', sep='\\t', header=None, names=['Label', 'Abstract'])\n",
    "test_df = pd.read_csv('../test.dat', sep='\\t', header=None, names=['Abstract'])\n",
    "submission_df = pd.read_csv('../format.dat', header=None, names=['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.608040Z",
     "start_time": "2018-10-01T05:19:13.597228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Catheterization laboratory events and hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Renal abscess in children. Three cases of rena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hyperplastic polyps seen at sigmoidoscopy are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Subclavian artery to innominate vein fistula a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Effect of local inhibition of gamma-aminobutyr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Abstract\n",
       "0      4  Catheterization laboratory events and hospital...\n",
       "1      5  Renal abscess in children. Three cases of rena...\n",
       "2      2  Hyperplastic polyps seen at sigmoidoscopy are ...\n",
       "3      5  Subclavian artery to innominate vein fistula a...\n",
       "4      4  Effect of local inhibition of gamma-aminobutyr..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.617844Z",
     "start_time": "2018-10-01T05:19:13.609766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excision of limbal dermoids. We reviewed the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bell's palsy. A diagnosis of exclusion. In cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retained endobronchial foreign body removal fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recurrent buccal space abscesses: a complicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intracranial fibromatosis. Fibromatoses are un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract\n",
       "0  Excision of limbal dermoids. We reviewed the c...\n",
       "1  Bell's palsy. A diagnosis of exclusion. In cas...\n",
       "2  Retained endobronchial foreign body removal fa...\n",
       "3  Recurrent buccal space abscesses: a complicati...\n",
       "4  Intracranial fibromatosis. Fibromatoses are un..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.624262Z",
     "start_time": "2018-10-01T05:19:13.619894Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine train and test abstracts to use for building vectorizer\n",
    "abstract_df = pd.concat([train_df['Abstract'], test_df['Abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.630465Z",
     "start_time": "2018-10-01T05:19:13.626169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28880,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "- See other notebook for detailed EDA \n",
    "    - [exploratory-data-analysis.ipynb]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Going to use `Bag of Words` approach\n",
    "    - presence of words (frequency or count) is taken into consideration & order is ignored\n",
    "    - BOW basically breaks up the note into the individual words and counts how many times each word occurs.\n",
    "- Tokenizer and a vectorizer. \n",
    "    - The tokenizer breaks a single abstract into a list of words and a vectorizer takes a list of words and counts the words.\n",
    "- `Tokenizer`:\n",
    "    - Remove punctuation & numbers\n",
    "    - Lowercase everything\n",
    "    - Two approaches for tokenization\n",
    "        - Goal is reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "        - `WordNetLemmatizer`\n",
    "            - Lemmatize all the text (e.g. women will become woman)\n",
    "                - Lemmatization is the process of converting the words of a sentence to its dictionary form. \n",
    "        - `PorterStemmer`\n",
    "            - Stem all the text\n",
    "                - Stemming is the process of converting words to the stem (root) of the word\n",
    "- `Vectorizer`:\n",
    "    - General process of turning a collection of text documents into numerical feature vectors. \n",
    "    - This specific strategy (tokenization, counting and normalization) is called the Bag of Words or “Bag of n-grams” representation. \n",
    "    - Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "    - `CountVectorizer`\n",
    "        - Encodes a vector with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "        - `vocabulary_` is a dict/mapping of the terms to their indices in the document-term matrix, not the counts.\n",
    "    - `TfidfVectorizer`\n",
    "        - Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "            - Normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents.\n",
    "        - TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "            - *This can be extremely useful for this problem, since we have 5 categories we are trying to classify and thus certain categories (medical conditions) may have words in the medical abstract that are unique to the condition*\n",
    "        - The resulting tf-idf vectors are then normalized by the Euclidean norm (L2)\n",
    "        - **Since the medical text data have a lot of multi-word expressions (e.g. *left anterior descending coronary artery*), I will use N-grams (where N >= 1) to keep the local positioning of these important words **\n",
    "            - Experimented with N-grams, and it seems 1-gram, 2-gram, 3-gram, and 4-grams produce best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.688068Z",
     "start_time": "2018-10-01T05:19:13.632463Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemma_tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    # Use Lemma tokenizer to tokenize the words\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lemmas = [lemma.lemmatize(word.strip()) for word in text.split()]\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "def word_tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def tokenizer(text):\n",
    "    '''Tokenize text into a list of preprocessed words '''\n",
    "    \n",
    "    # Create a string with all punctuations & digits concatenated\n",
    "    num_and_punc = string.punctuation + string.digits\n",
    "    \n",
    "    # Create a mapping to space using string above for each num/punc & return a translation table with mapping\n",
    "    t_table = str.maketrans(dict.fromkeys(num_and_punc, \" \"))\n",
    "    \n",
    "    # Lower text and use translation table to remove all punctuation and digits\n",
    "    text = text.lower().translate(t_table)\n",
    "    # Best Stemmer for this dataset (Tested)\n",
    "    stemmer = PorterStemmer()\n",
    "#     stemmer = SnowballStemmer(\"english\")\n",
    "#     stemmer = LancasterStemmer()\n",
    "    stems = [stemmer.stem(word.strip()) for word in text.split()]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.695893Z",
     "start_time": "2018-10-01T05:19:13.690132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create stop words list & remove unimportant words such as 'the' or 'and'\n",
    "\n",
    "# 153 stop words from NLTK\n",
    "nltk_stop_words = stopwords.words('english')\n",
    "# Combine stop words from all the stop word lists\n",
    "stop_words = ENGLISH_STOP_WORDS.union(nltk_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:19:13.703241Z",
     "start_time": "2018-10-01T05:19:13.698218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 381 stop words\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:20:56.352197Z",
     "start_time": "2018-10-01T05:19:13.705275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset({'three', 'doing', 'since', 'meanwhile', 'most', 'mostly', 'part', 'toward', 'whose', 'third', 'inc', 'could', 'noone', 'but', 'in', 'nevertheless', 'and', 'please', 'down', 'having', 'mine', 'm', 'go', 'together', 'something', 'the', 'ourselves', 'them', 'whence', 'latterly', '... 'such', 's', \"won't\", 'ma', 'against', 'besides', 'anyway', 'same', 'few', 'for', 'alone', 'show'}),\n",
       "        strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizer at 0x1071c0ea0>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using tf-idf\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(tokenizer = tokenizer, norm='l2', ngram_range=(1,2), sublinear_tf = True, min_df = 5,\n",
    "                            stop_words = stop_words)\n",
    "tfidf_vec.fit(abstract_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.699460Z",
     "start_time": "2018-10-01T05:20:56.354400Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.transform(train_df['Abstract'].values)\n",
    "X_test_tfidf = tfidf_vec.transform(test_df['Abstract'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.704232Z",
     "start_time": "2018-10-01T05:22:35.701373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 102346 features\n"
     ]
    }
   ],
   "source": [
    "print('There are %i features' % X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.712165Z",
     "start_time": "2018-10-01T05:22:35.706757Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = train_df['Label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-NN classifier\n",
    "\n",
    "- KNN is a lazy, nonparametric, instance based classifier \n",
    "- Using cosine distance as the distance metric for kNN\n",
    "    - Good when using bag of words with tf-idf\n",
    "    - Have to normalize vectors when using cosine similarity (which `TfidfVectorizer` does already with L2 normalization)\n",
    "- Uses majority voting of K nearest neighbors to determine the label of an instance\n",
    "- If there is a stalemate, I use the instances of the labels that tied, and calculate their inverse distance squared to determine the final winner\n",
    "    - A higher inverse squared distance score correlates with a higher similarity (farther distance squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.727361Z",
     "start_time": "2018-10-01T05:22:35.714711Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distance Metrics.\n",
    "\n",
    "Compute the distance between two items (usually strings).\n",
    "As metrics, they must satisfy the following three requirements:\n",
    "\n",
    "1. d(a, a) = 0\n",
    "2. d(a, b) >= 0\n",
    "3. d(a, c) <= d(a, b) + d(b, c)\n",
    "\"\"\"\n",
    "    \n",
    "def cosine_similarity_sparse(s1, s2):\n",
    "    '''Calculate cosine similiarity of two sparse matrices'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    numerator = s1.dot(s2.T)\n",
    "    return numerator\n",
    "\n",
    "def cosine_distance_sparse(s1, s2):\n",
    "    '''Calculate cosine distance of two sparse matrices (1 - cosine_similarity)'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    cos_sim = s1.dot(s2.T)\n",
    "    if s1.shape[0] > s2.shape[0]:\n",
    "        one_array = np.ones((s1.shape[0], 1), dtype=float)\n",
    "    else:\n",
    "        one_array = np.ones((s2.shape[0], 1), dtype=float)\n",
    "    return csr_matrix(one_array - cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.747018Z",
     "start_time": "2018-10-01T05:22:35.729973Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(features, labels, fold_num = 1, fold=10):\n",
    "    n = features.shape[0]\n",
    "    fold_size = int(np.ceil(n*1.0/fold))\n",
    "    feats = []\n",
    "    cls_train = []\n",
    "    for f in range(fold):\n",
    "        if f+1 != fold_num:\n",
    "            feats.append(features[f*fold_size: min((f+1)*fold_size, n)])\n",
    "            cls_train.extend(labels[f*fold_size: min((f+1)*fold_size, n)])\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(feats, format='csr')\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "    test = features[(fold_num-1)*fold_size: min(fold_num*fold_size, n), :]\n",
    "    cls_test = labels[(fold_num-1)*fold_size: min(fold_num*fold_size, n)]\n",
    "    return train, cls_train, test, cls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.828268Z",
     "start_time": "2018-10-01T05:22:35.749421Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics (Accuracy & F1 Score Functions)\n",
    "\n",
    "def calculate_accuracy(label, prediction):\n",
    "    '''Takes two numpy arrays or Python lists and produces an accuracy score in %'''\n",
    "    if isinstance(label, np.ndarray) and isinstance(prediction, np.ndarray):\n",
    "        assert label.shape == prediction.shape\n",
    "        return (label == prediction).all().mean() * 100.0\n",
    "    elif isinstance(label, list) and isinstance(prediction, list):\n",
    "        assert len(label) == len(prediction)\n",
    "        return sum(1 for a,b in zip(label, prediction) if a == b) / len(label)\n",
    "    else:\n",
    "        raise AttributeError('Both arguments have to be lists or numpy arrays')\n",
    "\n",
    "def calculate_weighted_f1_score(label, prediction):\n",
    "    if isinstance(label, np.ndarray) or isinstance(prediction, np.ndarray):\n",
    "        label = label.tolist()\n",
    "        prediction = prediction.tolist()\n",
    "    f1_list = []\n",
    "    label_dict = Counter(label)\n",
    "    label_dict = sorted(label_dict.items(), key=lambda x: x[0])\n",
    "    for l, support in label_dict:\n",
    "        tp = 0.\n",
    "        fp = 0.\n",
    "        tn = 0.\n",
    "        fn = 0.\n",
    "        for i in range(len(label)):\n",
    "            if prediction[i] == l:\n",
    "                if prediction[i] == label[i]:\n",
    "                    tp += 1.\n",
    "                else:\n",
    "                    fp += 1.\n",
    "            else:\n",
    "                if label[i] == l:\n",
    "                    fn += 1.\n",
    "        # precision is \"how useful the search results are\"\n",
    "        precision = tp / (tp + fp)\n",
    "        # recall is \"how complete the results are\"\n",
    "        recall = tp / (tp + fn)\n",
    "        \n",
    "        if precision == 0.0 or recall == 0.0:\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        weighted_f1_score = f1_score * support\n",
    "        f1_list.append(weighted_f1_score)\n",
    "    return sum(f1_list) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.883772Z",
     "start_time": "2018-10-01T05:22:35.830167Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_condition(train, labels, instance, K=5, metric = 'cosine'):\n",
    "    '''Using a distance metric to classify an instance'''\n",
    "    if metric == 'cosine':\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "    elif metric == 'euclidean':\n",
    "        dots = euclidean_distance_sparse(train, instance)\n",
    "    # Edit below later on\n",
    "    elif metric == 'jaccard':\n",
    "        dots = csr_matrix(cdist(train.toarray(), instance.toarray(), 'jaccard'))\n",
    "    else:\n",
    "        dots = cosine_distance_sparse(train, instance)\n",
    "        \n",
    "        \n",
    "    neighbors = list(zip(dots.indptr, dots.data))\n",
    "    if len(neighbors) == 0:\n",
    "        # could not find any neighbors\n",
    "        print('Could not find any neighbors.... Choosing a random one')\n",
    "        return np.asscalar(np.random.randint(low=1, high=5, size=1))\n",
    "    neighbors.sort(key=lambda x: x[1], reverse=False)        \n",
    "        \n",
    "    tc = Counter(labels[s[0]] for s in neighbors[:K]).most_common(5)\n",
    "    \n",
    "    if len(tc) == 1 or tc[0][1] > tc[1][1]:\n",
    "        # majority vote\n",
    "        return tc[0][0]\n",
    "\n",
    "    # tie break\n",
    "    # Only keep tied labels\n",
    "    num_n = tc[0][1]\n",
    "    keep_labels = [l for l, c in tc if c == num_n]\n",
    "    tc = defaultdict(float)\n",
    "     # Distance-Weighted Voting \n",
    "    for s in neighbors[:K]:\n",
    "        if labels[s[0]] not in keep_labels:\n",
    "            continue\n",
    "        else:\n",
    "            tc[labels[s[0]]] += (1 / (s[1]**2))\n",
    "            \n",
    "    return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.908497Z",
     "start_time": "2018-10-01T05:22:35.886163Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(features, labels, metric='cosine', K=3, fold=10):\n",
    "    '''Using KFold Cross Validation to evaluate model accuracy'''\n",
    "    \n",
    "    if metric not in ['cosine', 'euclidean', 'jaccard', 'hamming', 'mahalanobis']:\n",
    "        raise ValueError('Metric must be `cosine`, `euclidean`, or `jaccard`')\n",
    "    \n",
    "    macc = 0.0\n",
    "    cum_f1 = 0.0\n",
    "    for f in range(fold):\n",
    "        # split data into training and testing\n",
    "        train_set, train_labels, test_set, test_labels = split_data(features, labels, f+1, fold)\n",
    "        # predict the class of each test sample\n",
    "        predictions = np.array([classify_condition(train_set, train_labels, test_set[i,:], K=K, metric=metric) \n",
    "                       for i in range(test_set.shape[0])])\n",
    "        acc = calculate_accuracy(test_labels, predictions)\n",
    "        f1 = calculate_weighted_f1_score(test_labels, predictions)\n",
    "#         print('Fold-%i Accuracy: %.05f' % (f+1, acc))\n",
    "        print('Fold-%i F1 Score: %.05f' % (f+1, f1))\n",
    "        macc += acc\n",
    "        cum_f1 += f1\n",
    "    \n",
    "    return macc/float(fold), cum_f1/float(fold)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score 10-Fold CV Total Time Taken\n",
    "\n",
    "- My F1 score implementation (with Python lists): 17 minutes 5 seconds\n",
    "- Sklearn's F1 score implementation (with sparse matrices): 16 minutes 50 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameter K\n",
    "\n",
    "- Implementation of simple grid search through various values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:22:35.923755Z",
     "start_time": "2018-10-01T05:22:35.910293Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(features, labels, start, end, inc=1):\n",
    "    '''My Grid Search Function'''\n",
    "    best_f1 = 0.0\n",
    "    best_k = 0\n",
    "    best_acc = 0.0\n",
    "    for k in np.arange(start, end, inc):\n",
    "        acc, f1 = evaluate_model(features, labels, K=k, fold=10)\n",
    "#         print('For %i-NN, 10-Fold CV Average Accuracy: %.05f%%' % (k, acc * 100.0)) \n",
    "        print('For %i-NN, 10-Fold CV Weighted F1 Score: %.05f' % (k, f1)) \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_acc = acc\n",
    "            best_k = k\n",
    "    \n",
    "    print('Best Model Params: \\n For %d-NN, 10-Fold CV Weighted F1 Score: %.08f'% (best_k, best_f1))\n",
    "    return best_k, best_acc, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T05:52:42.043706Z",
     "start_time": "2018-10-01T05:22:35.926108Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1 F1 Score: 0.59009\n",
      "Fold-2 F1 Score: 0.55275\n",
      "Fold-3 F1 Score: 0.59362\n",
      "Fold-4 F1 Score: 0.58700\n",
      "Fold-5 F1 Score: 0.55823\n",
      "Fold-6 F1 Score: 0.55579\n",
      "Fold-7 F1 Score: 0.57637\n",
      "Fold-8 F1 Score: 0.58548\n",
      "Fold-9 F1 Score: 0.60081\n",
      "Fold-10 F1 Score: 0.56672\n",
      "For 10-NN, 10-Fold CV Weighted F1 Score: 0.57669\n",
      "Fold-1 F1 Score: 0.61077\n",
      "Fold-2 F1 Score: 0.59988\n",
      "Fold-3 F1 Score: 0.63196\n",
      "Fold-4 F1 Score: 0.62812\n",
      "Fold-5 F1 Score: 0.59606\n",
      "Fold-6 F1 Score: 0.60076\n",
      "Fold-7 F1 Score: 0.61644\n",
      "Fold-8 F1 Score: 0.60074\n",
      "Fold-9 F1 Score: 0.62812\n",
      "Fold-10 F1 Score: 0.59928\n",
      "For 20-NN, 10-Fold CV Weighted F1 Score: 0.61121\n",
      "Fold-1 F1 Score: 0.62113\n",
      "Fold-2 F1 Score: 0.60573\n",
      "Fold-3 F1 Score: 0.64153\n",
      "Fold-4 F1 Score: 0.62352\n",
      "Fold-5 F1 Score: 0.61051\n",
      "Fold-6 F1 Score: 0.61743\n",
      "Fold-7 F1 Score: 0.62152\n",
      "Fold-8 F1 Score: 0.62059\n",
      "Fold-9 F1 Score: 0.63246\n",
      "Fold-10 F1 Score: 0.60440\n",
      "For 30-NN, 10-Fold CV Weighted F1 Score: 0.61988\n",
      "Fold-1 F1 Score: 0.61938\n",
      "Fold-2 F1 Score: 0.60805\n",
      "Fold-3 F1 Score: 0.64839\n",
      "Fold-4 F1 Score: 0.62584\n",
      "Fold-5 F1 Score: 0.61291\n",
      "Fold-6 F1 Score: 0.62037\n",
      "Fold-7 F1 Score: 0.62148\n",
      "Fold-8 F1 Score: 0.60966\n",
      "Fold-9 F1 Score: 0.63651\n",
      "Fold-10 F1 Score: 0.61665\n",
      "For 40-NN, 10-Fold CV Weighted F1 Score: 0.62192\n",
      "Fold-1 F1 Score: 0.61849\n",
      "Fold-2 F1 Score: 0.60889\n",
      "Fold-3 F1 Score: 0.64315\n",
      "Fold-4 F1 Score: 0.63065\n",
      "Fold-5 F1 Score: 0.61679\n",
      "Fold-6 F1 Score: 0.61647\n",
      "Fold-7 F1 Score: 0.62137\n",
      "Fold-8 F1 Score: 0.61373\n",
      "Fold-9 F1 Score: 0.63896\n",
      "Fold-10 F1 Score: 0.60964\n",
      "For 50-NN, 10-Fold CV Weighted F1 Score: 0.62181\n",
      "Fold-1 F1 Score: 0.61331\n",
      "Fold-2 F1 Score: 0.60990\n",
      "Fold-3 F1 Score: 0.64544\n",
      "Fold-4 F1 Score: 0.63109\n",
      "Fold-5 F1 Score: 0.60577\n",
      "Fold-6 F1 Score: 0.61434\n",
      "Fold-7 F1 Score: 0.61868\n",
      "Fold-8 F1 Score: 0.60707\n",
      "Fold-9 F1 Score: 0.64260\n",
      "Fold-10 F1 Score: 0.61124\n",
      "For 60-NN, 10-Fold CV Weighted F1 Score: 0.61994\n",
      "Fold-1 F1 Score: 0.61724\n",
      "Fold-2 F1 Score: 0.61342\n",
      "Fold-3 F1 Score: 0.64215\n",
      "Fold-4 F1 Score: 0.62469\n",
      "Fold-5 F1 Score: 0.60250\n",
      "Fold-6 F1 Score: 0.61830\n",
      "Fold-7 F1 Score: 0.61283\n",
      "Fold-8 F1 Score: 0.60913\n",
      "Fold-9 F1 Score: 0.62727\n",
      "Fold-10 F1 Score: 0.60856\n",
      "For 70-NN, 10-Fold CV Weighted F1 Score: 0.61761\n",
      "Best Model Params: \n",
      " For 40-NN, 10-Fold CV Weighted F1 Score: 0.62192334\n"
     ]
    }
   ],
   "source": [
    "K, acc, f1 = grid_search(X_train_tfidf, Y_train, start=10, end=80, inc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T07:16:22.866580Z",
     "start_time": "2018-10-01T05:53:41.603385Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1 F1 Score: 0.61799\n",
      "Fold-2 F1 Score: 0.61505\n",
      "Fold-3 F1 Score: 0.64072\n",
      "Fold-4 F1 Score: 0.62411\n",
      "Fold-5 F1 Score: 0.61014\n",
      "Fold-6 F1 Score: 0.61568\n",
      "Fold-7 F1 Score: 0.62191\n",
      "Fold-8 F1 Score: 0.61760\n",
      "Fold-9 F1 Score: 0.63629\n",
      "Fold-10 F1 Score: 0.61035\n",
      "For 31-NN, 10-Fold CV Weighted F1 Score: 0.62098\n",
      "Fold-1 F1 Score: 0.61890\n",
      "Fold-2 F1 Score: 0.61014\n",
      "Fold-3 F1 Score: 0.64308\n",
      "Fold-4 F1 Score: 0.62135\n",
      "Fold-5 F1 Score: 0.60524\n",
      "Fold-6 F1 Score: 0.61403\n",
      "Fold-7 F1 Score: 0.62449\n",
      "Fold-8 F1 Score: 0.62309\n",
      "Fold-9 F1 Score: 0.62782\n",
      "Fold-10 F1 Score: 0.60822\n",
      "For 32-NN, 10-Fold CV Weighted F1 Score: 0.61964\n",
      "Fold-1 F1 Score: 0.62120\n",
      "Fold-2 F1 Score: 0.60913\n",
      "Fold-3 F1 Score: 0.64411\n",
      "Fold-4 F1 Score: 0.61943\n",
      "Fold-5 F1 Score: 0.60486\n",
      "Fold-6 F1 Score: 0.61551\n",
      "Fold-7 F1 Score: 0.62617\n",
      "Fold-8 F1 Score: 0.62148\n",
      "Fold-9 F1 Score: 0.62819\n",
      "Fold-10 F1 Score: 0.61212\n",
      "For 33-NN, 10-Fold CV Weighted F1 Score: 0.62022\n",
      "Fold-1 F1 Score: 0.61705\n",
      "Fold-2 F1 Score: 0.61074\n",
      "Fold-3 F1 Score: 0.64294\n",
      "Fold-4 F1 Score: 0.62459\n",
      "Fold-5 F1 Score: 0.60317\n",
      "Fold-6 F1 Score: 0.61545\n",
      "Fold-7 F1 Score: 0.61882\n",
      "Fold-8 F1 Score: 0.61778\n",
      "Fold-9 F1 Score: 0.62397\n",
      "Fold-10 F1 Score: 0.61333\n",
      "For 34-NN, 10-Fold CV Weighted F1 Score: 0.61878\n",
      "Fold-1 F1 Score: 0.61056\n",
      "Fold-2 F1 Score: 0.61331\n",
      "Fold-3 F1 Score: 0.64184\n",
      "Fold-4 F1 Score: 0.62689\n",
      "Fold-5 F1 Score: 0.60627\n",
      "Fold-6 F1 Score: 0.61536\n",
      "Fold-7 F1 Score: 0.61971\n",
      "Fold-8 F1 Score: 0.61674\n",
      "Fold-9 F1 Score: 0.62784\n",
      "Fold-10 F1 Score: 0.61582\n",
      "For 35-NN, 10-Fold CV Weighted F1 Score: 0.61943\n",
      "Fold-1 F1 Score: 0.61674\n",
      "Fold-2 F1 Score: 0.61282\n",
      "Fold-3 F1 Score: 0.64434\n",
      "Fold-4 F1 Score: 0.62335\n",
      "Fold-5 F1 Score: 0.61170\n",
      "Fold-6 F1 Score: 0.61811\n",
      "Fold-7 F1 Score: 0.62197\n",
      "Fold-8 F1 Score: 0.60921\n",
      "Fold-9 F1 Score: 0.63120\n",
      "Fold-10 F1 Score: 0.61855\n",
      "For 36-NN, 10-Fold CV Weighted F1 Score: 0.62080\n",
      "Fold-1 F1 Score: 0.61800\n",
      "Fold-2 F1 Score: 0.61390\n",
      "Fold-3 F1 Score: 0.64490\n",
      "Fold-4 F1 Score: 0.62285\n",
      "Fold-5 F1 Score: 0.60711\n",
      "Fold-6 F1 Score: 0.62167\n",
      "Fold-7 F1 Score: 0.62136\n",
      "Fold-8 F1 Score: 0.61472\n",
      "Fold-9 F1 Score: 0.63714\n",
      "Fold-10 F1 Score: 0.61446\n",
      "For 37-NN, 10-Fold CV Weighted F1 Score: 0.62161\n",
      "Fold-1 F1 Score: 0.61585\n",
      "Fold-2 F1 Score: 0.61356\n",
      "Fold-3 F1 Score: 0.64476\n",
      "Fold-4 F1 Score: 0.62386\n",
      "Fold-5 F1 Score: 0.60728\n",
      "Fold-6 F1 Score: 0.61997\n",
      "Fold-7 F1 Score: 0.62076\n",
      "Fold-8 F1 Score: 0.61620\n",
      "Fold-9 F1 Score: 0.63280\n",
      "Fold-10 F1 Score: 0.61944\n",
      "For 38-NN, 10-Fold CV Weighted F1 Score: 0.62145\n",
      "Fold-1 F1 Score: 0.61836\n",
      "Fold-2 F1 Score: 0.61085\n",
      "Fold-3 F1 Score: 0.64839\n",
      "Fold-4 F1 Score: 0.62671\n",
      "Fold-5 F1 Score: 0.60523\n",
      "Fold-6 F1 Score: 0.62679\n",
      "Fold-7 F1 Score: 0.62191\n",
      "Fold-8 F1 Score: 0.61200\n",
      "Fold-9 F1 Score: 0.63670\n",
      "Fold-10 F1 Score: 0.61890\n",
      "For 39-NN, 10-Fold CV Weighted F1 Score: 0.62258\n",
      "Fold-1 F1 Score: 0.61938\n",
      "Fold-2 F1 Score: 0.60805\n",
      "Fold-3 F1 Score: 0.64839\n",
      "Fold-4 F1 Score: 0.62584\n",
      "Fold-5 F1 Score: 0.61291\n",
      "Fold-6 F1 Score: 0.62037\n",
      "Fold-7 F1 Score: 0.62148\n",
      "Fold-8 F1 Score: 0.60966\n",
      "Fold-9 F1 Score: 0.63651\n",
      "Fold-10 F1 Score: 0.61665\n",
      "For 40-NN, 10-Fold CV Weighted F1 Score: 0.62192\n",
      "Fold-1 F1 Score: 0.61667\n",
      "Fold-2 F1 Score: 0.60827\n",
      "Fold-3 F1 Score: 0.64660\n",
      "Fold-4 F1 Score: 0.62568\n",
      "Fold-5 F1 Score: 0.61150\n",
      "Fold-6 F1 Score: 0.61929\n",
      "Fold-7 F1 Score: 0.62220\n",
      "Fold-8 F1 Score: 0.61395\n",
      "Fold-9 F1 Score: 0.63157\n",
      "Fold-10 F1 Score: 0.61223\n",
      "For 41-NN, 10-Fold CV Weighted F1 Score: 0.62080\n",
      "Fold-1 F1 Score: 0.61650\n",
      "Fold-2 F1 Score: 0.60890\n",
      "Fold-3 F1 Score: 0.64445\n",
      "Fold-4 F1 Score: 0.63521\n",
      "Fold-5 F1 Score: 0.61332\n",
      "Fold-6 F1 Score: 0.62238\n",
      "Fold-7 F1 Score: 0.62021\n",
      "Fold-8 F1 Score: 0.61537\n",
      "Fold-9 F1 Score: 0.63950\n",
      "Fold-10 F1 Score: 0.61460\n",
      "For 42-NN, 10-Fold CV Weighted F1 Score: 0.62305\n",
      "Fold-1 F1 Score: 0.61986\n",
      "Fold-2 F1 Score: 0.60908\n",
      "Fold-3 F1 Score: 0.64331\n",
      "Fold-4 F1 Score: 0.63059\n",
      "Fold-5 F1 Score: 0.61501\n",
      "Fold-6 F1 Score: 0.62726\n",
      "Fold-7 F1 Score: 0.62116\n",
      "Fold-8 F1 Score: 0.61987\n",
      "Fold-9 F1 Score: 0.63264\n",
      "Fold-10 F1 Score: 0.61533\n",
      "For 43-NN, 10-Fold CV Weighted F1 Score: 0.62341\n",
      "Fold-1 F1 Score: 0.61929\n",
      "Fold-2 F1 Score: 0.60467\n",
      "Fold-3 F1 Score: 0.64156\n",
      "Fold-4 F1 Score: 0.62982\n",
      "Fold-5 F1 Score: 0.61477\n",
      "Fold-6 F1 Score: 0.62573\n",
      "Fold-7 F1 Score: 0.62115\n",
      "Fold-8 F1 Score: 0.61612\n",
      "Fold-9 F1 Score: 0.64005\n",
      "Fold-10 F1 Score: 0.61345\n",
      "For 44-NN, 10-Fold CV Weighted F1 Score: 0.62266\n",
      "Fold-1 F1 Score: 0.61790\n",
      "Fold-2 F1 Score: 0.60838\n",
      "Fold-3 F1 Score: 0.64243\n",
      "Fold-4 F1 Score: 0.63555\n",
      "Fold-5 F1 Score: 0.61712\n",
      "Fold-6 F1 Score: 0.62398\n",
      "Fold-7 F1 Score: 0.61614\n",
      "Fold-8 F1 Score: 0.61698\n",
      "Fold-9 F1 Score: 0.63747\n",
      "Fold-10 F1 Score: 0.61704\n",
      "For 45-NN, 10-Fold CV Weighted F1 Score: 0.62330\n",
      "Fold-1 F1 Score: 0.61774\n",
      "Fold-2 F1 Score: 0.60064\n",
      "Fold-3 F1 Score: 0.63799\n",
      "Fold-4 F1 Score: 0.63391\n",
      "Fold-5 F1 Score: 0.61483\n",
      "Fold-6 F1 Score: 0.62392\n",
      "Fold-7 F1 Score: 0.61521\n",
      "Fold-8 F1 Score: 0.61809\n",
      "Fold-9 F1 Score: 0.63713\n",
      "Fold-10 F1 Score: 0.61686\n",
      "For 46-NN, 10-Fold CV Weighted F1 Score: 0.62163\n",
      "Fold-1 F1 Score: 0.61890\n",
      "Fold-2 F1 Score: 0.60876\n",
      "Fold-3 F1 Score: 0.64064\n",
      "Fold-4 F1 Score: 0.63726\n",
      "Fold-5 F1 Score: 0.60597\n",
      "Fold-6 F1 Score: 0.62282\n",
      "Fold-7 F1 Score: 0.61569\n",
      "Fold-8 F1 Score: 0.61290\n",
      "Fold-9 F1 Score: 0.63042\n",
      "Fold-10 F1 Score: 0.62121\n",
      "For 47-NN, 10-Fold CV Weighted F1 Score: 0.62146\n",
      "Fold-1 F1 Score: 0.61809\n",
      "Fold-2 F1 Score: 0.60881\n",
      "Fold-3 F1 Score: 0.64040\n",
      "Fold-4 F1 Score: 0.63853\n",
      "Fold-5 F1 Score: 0.61287\n",
      "Fold-6 F1 Score: 0.61797\n",
      "Fold-7 F1 Score: 0.61941\n",
      "Fold-8 F1 Score: 0.61487\n",
      "Fold-9 F1 Score: 0.63396\n",
      "Fold-10 F1 Score: 0.61389\n",
      "For 48-NN, 10-Fold CV Weighted F1 Score: 0.62188\n",
      "Fold-1 F1 Score: 0.61839\n",
      "Fold-2 F1 Score: 0.60460\n",
      "Fold-3 F1 Score: 0.64104\n",
      "Fold-4 F1 Score: 0.63370\n",
      "Fold-5 F1 Score: 0.61438\n",
      "Fold-6 F1 Score: 0.61917\n",
      "Fold-7 F1 Score: 0.62267\n",
      "Fold-8 F1 Score: 0.61358\n",
      "Fold-9 F1 Score: 0.63506\n",
      "Fold-10 F1 Score: 0.61762\n",
      "For 49-NN, 10-Fold CV Weighted F1 Score: 0.62202\n",
      "Best Model Params: \n",
      " For 43-NN, 10-Fold CV Weighted F1 Score: 0.62341133\n"
     ]
    }
   ],
   "source": [
    "K, acc, f1 = grid_search(X_train_tfidf, Y_train, start=K-9, end=K+10, inc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T07:16:22.874018Z",
     "start_time": "2018-10-01T07:16:22.868656Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_condition(X_train, Y_train, X_test, K):\n",
    "    predictions = np.array([classify_condition(X_train, Y_train, X_test[i,:], K=K, metric='cosine') \n",
    "                       for i in range(X_test.shape[0])])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T07:21:33.053495Z",
     "start_time": "2018-10-01T07:16:22.876380Z"
    }
   },
   "outputs": [],
   "source": [
    "final_predictions = predict_condition(X_train_tfidf, Y_train, X_test_tfidf, K = K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T07:21:33.058534Z",
     "start_time": "2018-10-01T07:21:33.055331Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df['Labels'] = final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T07:32:51.401310Z",
     "start_time": "2018-10-01T07:32:51.351868Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.txt', sep='\\n', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
