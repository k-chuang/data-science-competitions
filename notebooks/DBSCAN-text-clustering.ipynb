{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR3: Text Clustering with DBSCAN\n",
    "\n",
    "* Author: Kevin Chuang [@k-chuang](https://www.github.com/k-chuang)\n",
    "* Created on: September 21, 2018\n",
    "* Description: Text clustering using DBCAN clustering algorithm\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:46.205476Z",
     "start_time": "2018-11-30T00:50:44.728962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.0.\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# OS & sys\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Version check\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Manifold Learning\n",
    "from sklearn.manifold import LocallyLinearEmbedding, TSNE\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, chi2, RFECV, SelectFromModel, RFE\n",
    "\n",
    "# Text Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Metrics \n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Model Selection & Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space  import Real, Categorical, Integer\n",
    "\n",
    "# Decomposition\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, KernelPCA, NMF, FactorAnalysis, FastICA\n",
    "\n",
    "# Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Mathematical Functions\n",
    "import math\n",
    "\n",
    "# Utils\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats, sparse\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:46.240797Z",
     "start_time": "2018-11-30T00:50:46.207235Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('train.dat', 'r') as fh:\n",
    "#     data = fh.readlines()\n",
    "    data = fh.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:46.251113Z",
     "start_time": "2018-11-30T00:50:46.243966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:46.258378Z",
     "start_time": "2018-11-30T00:50:46.254255Z"
    }
   },
   "outputs": [],
   "source": [
    "def grouped(iterable, n):\n",
    "    return zip(*[iter(iterable)]*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:47.417200Z",
     "start_time": "2018-11-30T00:50:46.262415Z"
    }
   },
   "outputs": [],
   "source": [
    "row_pairs = []\n",
    "inds = []\n",
    "vals = []\n",
    "ptrs = [0]\n",
    "for row_idx, row in enumerate(data):\n",
    "    \n",
    "    document = row.strip().split()\n",
    "    if len(document) % 2 != 0:\n",
    "        raise ValueError(\"document length is not correct...\")\n",
    "    doc_length = len(document)//2\n",
    "    \n",
    "    ptrs.append(ptrs[-1] + doc_length)\n",
    "    for index, count in grouped(row.split(), 2):\n",
    "#         row_pairs.append((index, count))\n",
    "        inds.append(int(index))\n",
    "        vals.append(int(count))\n",
    "#         print(int(index), int(count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:47.673534Z",
     "start_time": "2018-11-30T00:50:47.424531Z"
    }
   },
   "outputs": [],
   "source": [
    "data_csr = sparse.csr_matrix((vals,inds,ptrs), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:47.803873Z",
     "start_time": "2018-11-30T00:50:47.783526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the words that only appear in a few documents (or no documents) and all documents.\n",
    "def remove_words(doc_term_matrix, min_df):\n",
    "    remove_word_cols = []\n",
    "    for col_ind in np.arange(0, doc_term_matrix.shape[1]):\n",
    "        doc_count = doc_term_matrix[:, col_ind].count_nonzero()\n",
    "    #     print(doc_count)\n",
    "        if doc_count <= min_df:\n",
    "            remove_word_cols.append(col_ind)\n",
    "    #         print(\"Found word with less than 3 appearances...\")\n",
    "        if doc_count > int(float(doc_term_matrix.shape[0]) * .95):\n",
    "            remove_word_cols.append(col_ind)\n",
    "            print(\"Found word appearing in 95% of documents\")\n",
    "        if doc_count == doc_term_matrix.shape[0]:\n",
    "            remove_word_cols.append(col_ind)\n",
    "            print(\"Found word appearing in all documents at %d\" % col_ind)\n",
    "    return remove_word_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:51.617388Z",
     "start_time": "2018-11-30T00:50:51.469181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word transformer\n",
    "# X = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True).fit_transform(data_csr)\n",
    "X = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False).fit_transform(data_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:52.012826Z",
     "start_time": "2018-11-30T00:50:52.008005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8580, 126356)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:54.712882Z",
     "start_time": "2018-11-30T00:50:54.480274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Goal is to minmize squared reconstruction error\n",
    "selector = TruncatedSVD(n_components=5, algorithm=\"arpack\", random_state=8)\n",
    "X = selector.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:58.921745Z",
     "start_time": "2018-11-30T00:50:58.917834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8580, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:59.408218Z",
     "start_time": "2018-11-30T00:50:59.403305Z"
    }
   },
   "outputs": [],
   "source": [
    "X = sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:50:59.816545Z",
     "start_time": "2018-11-30T00:50:59.789343Z"
    }
   },
   "outputs": [],
   "source": [
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = float(1.0/np.sqrt(rsum))\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:00.127041Z",
     "start_time": "2018-11-30T00:51:00.056190Z"
    }
   },
   "outputs": [],
   "source": [
    "X = csr_l2normalize(X, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:00.295344Z",
     "start_time": "2018-11-30T00:51:00.279273Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_sparse(s1, s2):\n",
    "    '''Calculate cosine similiarity of two sparse matrices'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    numerator = s1.dot(s2.T)\n",
    "    return numerator\n",
    "\n",
    "\n",
    "def cosine_distance_sparse(s1, s2):\n",
    "    '''Calculate cosine distance of two sparse matrices (1 - cosine_similarity)'''\n",
    "    # Calculate dot product (already L2 norm vectors so we do not need to divide)\n",
    "    cos_sim = s1.dot(s2.T)\n",
    "#     print(cos_sim.shape)\n",
    "    if s1.shape[0] > s2.shape[0]:\n",
    "        one_array = np.ones((s1.shape[0], 1), dtype=float)\n",
    "    else:\n",
    "        one_array = np.ones((s2.shape[0], 1), dtype=float)\n",
    "    return np.array(one_array - cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:00.486696Z",
     "start_time": "2018-11-30T00:51:00.481027Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_neighbors(data, query, eps):\n",
    "    distances = cosine_distance_sparse(data, query)\n",
    "    indices = np.arange(data.shape[0])\n",
    "    neighbors = indices[np.ravel(distances < eps)]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:00.752579Z",
     "start_time": "2018-11-30T00:51:00.686133Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_cluster(data, labels, q, neighbors, c_id, eps, minPts, border_pts):\n",
    "   \n",
    "    labels[q] = c_id\n",
    "    i = 0\n",
    "    while i < len(neighbors):    \n",
    "        new_point = neighbors[i]\n",
    "        if labels[new_point] == -1:\n",
    "            labels[new_point] = c_id\n",
    "            border_pts.append(new_point)\n",
    "        \n",
    "        elif labels[new_point] == 0:\n",
    "            labels[new_point] = c_id\n",
    "            \n",
    "            new_neighbors = find_neighbors(data, data[new_point], eps)\n",
    "            if len(new_neighbors) >= minPts:\n",
    "                neighbors = np.concatenate((neighbors, new_neighbors), axis=None)\n",
    "        i += 1        \n",
    "        \n",
    "    return labels, border_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:00.931489Z",
     "start_time": "2018-11-30T00:51:00.879962Z"
    }
   },
   "outputs": [],
   "source": [
    "def DBSCAN(data, eps, minPts):\n",
    "    labels = np.zeros(data.shape[0], dtype=int)\n",
    "    c_id = 0\n",
    "    \n",
    "    core_pts = []\n",
    "    border_pts = []\n",
    "    \n",
    "    for q in range(0, data.shape[0]):\n",
    "\n",
    "        if labels[q] != 0:\n",
    "            continue\n",
    "\n",
    "        neighbors = find_neighbors(data, data[q], eps)\n",
    "        if len(neighbors) < minPts:\n",
    "            labels[q] = -1\n",
    "        else: \n",
    "            c_id += 1\n",
    "            core_pts.append(q)\n",
    "            labels, border_pts = generate_cluster(data, labels, q, neighbors, c_id, eps, minPts, border_pts)\n",
    "    return labels, core_pts, border_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:01.123636Z",
     "start_time": "2018-11-30T00:51:01.060662Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_noise_cluster(data, ids, K=5):\n",
    "    \"\"\"Use K nearest neighbors and majority voting to assign noise points to potential new clusters\"\"\"\n",
    "    noise_ind = np.argwhere(ids==-1).ravel()\n",
    "    n_clusters_ = len(set(ids)) - (1 if -1 in ids else 0)\n",
    "    for q in noise_ind:\n",
    "        distances = cosine_distance_sparse(data, data[q])\n",
    "        neighbors = np.argsort(distances.ravel())[1:K+1]\n",
    "        neighbor_ids = ids[neighbors]\n",
    "        optimal_dists = distances[neighbors]\n",
    "        count = Counter(neighbor_ids).most_common()\n",
    "        if len(count) == 1 or count[0][1] > count[1][1]:\n",
    "            if count[0][0] == -1:\n",
    "                ids[q] = n_clusters_ + 1\n",
    "            else:\n",
    "#                 print(\"Found a simliar noise point to a existing cluster\")\n",
    "                ids[q] = count[0][0]\n",
    "            continue\n",
    "        num_n = count[0][1]\n",
    "        keep_ids = [l for l, c in count if c == num_n]\n",
    "        tc = defaultdict(float)\n",
    "        # Distance-Weighted Voting\n",
    "        for c_id, dist in zip(neighbor_ids, optimal_dists):\n",
    "            if c_id not in keep_ids:\n",
    "                continue\n",
    "            else:\n",
    "                tc[c_id] += (1 / (dist ** 2))\n",
    "        if sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0] == -1:\n",
    "            ids[q] = n_clusters_ + 1\n",
    "        else:\n",
    "#             print(\"Found a simliar noise point to a existing cluster\")\n",
    "            ids[q] = sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:01.314165Z",
     "start_time": "2018-11-30T00:51:01.263551Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_noise_KNN(data, ids, K=5):\n",
    "    \"\"\"Use K nearest neighbors and majority voting to assign noise points to existing clusters\"\"\"\n",
    "    noise_ind = np.argwhere(ids==-1).ravel()\n",
    "    no_noise_data = data[np.where(ids!=-1)]\n",
    "    no_noise_ids = ids[np.where(ids!=-1)]\n",
    "    for q in noise_ind:\n",
    "        distances = cosine_distance_sparse(no_noise_data, data[q])\n",
    "        pseudo_neighbors = np.argsort(distances.ravel())[:K]\n",
    "        neighbor_ids = no_noise_ids[pseudo_neighbors]\n",
    "        optimal_dists = distances[pseudo_neighbors]\n",
    "\n",
    "        count = Counter(neighbor_ids).most_common()\n",
    "#         print(count)\n",
    "        if len(count) == 1 or count[0][1] > count[1][1]:\n",
    "            ids[q] = count[0][0]\n",
    "            continue\n",
    "        num_n = count[0][1]\n",
    "        keep_ids = [l for l, c in count if c == num_n]\n",
    "        tc = defaultdict(float)\n",
    "        # Distance-Weighted Voting\n",
    "        for c_id, dist in zip(neighbor_ids, optimal_dists):\n",
    "            if c_id not in keep_ids:\n",
    "                continue\n",
    "            else:\n",
    "                tc[c_id] += (1 / (dist ** 2))\n",
    "        ids[q] = sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:01.447209Z",
     "start_time": "2018-11-30T00:51:01.429903Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_noise_to_core(data, ids, core_pts, border_pts):\n",
    "    noise_ind = np.argwhere(ids==-1).ravel()\n",
    "    no_noise_ind = np.argwhere(ids!=-1).ravel()\n",
    "    no_noise_data = data[np.where(ids!=-1)]\n",
    "    no_noise_ids = ids[np.where(ids!=-1)]\n",
    "    for q in noise_ind:\n",
    "        distances = cosine_distance_sparse(no_noise_data, data[q])\n",
    "        neighbors = np.argsort(distances.ravel())\n",
    "        nearest_core_ind = next((x for x in no_noise_ind[neighbors] if x in core_pts), -1)\n",
    "        ids[q] = ids[nearest_core_ind]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:01.679700Z",
     "start_time": "2018-11-30T00:51:01.663180Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_noise_to_border(data, ids, core_pts, border_pts):\n",
    "    noise_ind = np.argwhere(ids==-1).ravel()\n",
    "    no_noise_ind = np.argwhere(ids!=-1).ravel()\n",
    "    no_noise_data = data[np.where(ids!=-1)]\n",
    "    no_noise_ids = ids[np.where(ids!=-1)]\n",
    "    for q in noise_ind:\n",
    "        distances = cosine_distance_sparse(no_noise_data, data[q])\n",
    "        neighbors = np.argsort(distances.ravel())\n",
    "        nearest_core_ind = next((x for x in no_noise_ind[neighbors] if x in border_pts), -1)\n",
    "        ids[q] = ids[nearest_core_ind]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:02.568241Z",
     "start_time": "2018-11-30T00:51:02.552335Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_noise_to_closest(data, ids, core_pts, border_pts):\n",
    "    noise_ind = np.argwhere(ids==-1).ravel()\n",
    "    no_noise_ind = np.argwhere(ids!=-1).ravel()\n",
    "    no_noise_data = data[np.where(ids!=-1)]\n",
    "    no_noise_ids = ids[np.where(ids!=-1)]\n",
    "    core_border = core_pts + border_pts\n",
    "    for q in noise_ind:\n",
    "        distances = cosine_distance_sparse(no_noise_data, data[q])\n",
    "        neighbors = np.argsort(distances.ravel())\n",
    "        nearest_core_ind = next((x for x in no_noise_ind[neighbors] if x in core_border), -1)\n",
    "        ids[q] = ids[nearest_core_ind]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:03.216839Z",
     "start_time": "2018-11-30T00:51:03.201640Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_centroids(data, ids):\n",
    "    no_noise_ind = np.argwhere(ids!=-1).ravel()\n",
    "    no_noise_data = data[np.where(ids!=-1)]\n",
    "    no_noise_ids = ids[np.where(ids!=-1)]\n",
    "    n_clusters_ = len(set(ids)) - (1 if -1 in ids else 0)\n",
    "    c_ids = sorted([x for x in set(ids) if x != -1])\n",
    "    c_centroids = []\n",
    "    for c in c_ids:\n",
    "        cluster_data = data[np.where(ids==c)]\n",
    "        centroid = np.asarray(cluster_data.mean(axis=0)).ravel().tolist()\n",
    "        c_centroids.append(centroid)\n",
    "\n",
    "    return c_ids, sparse.csr_matrix(c_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:03.750441Z",
     "start_time": "2018-11-30T00:51:03.726700Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_noise_to_centroid(data, ids, recompute_centroid=False):\n",
    "    c_ids, c_centroids = calculate_centroids(data, ids)\n",
    "    \n",
    "    noise_ind = np.argwhere(ids==-1).ravel()\n",
    "    no_noise_ind = np.argwhere(ids!=-1).ravel()\n",
    "    no_noise_data = data[np.where(ids!=-1)]\n",
    "    no_noise_ids = ids[np.where(ids!=-1)]\n",
    "    for q in noise_ind:\n",
    "        distances = cosine_distance_sparse(c_centroids, data[q])\n",
    "#         print(distances.ravel()[0])\n",
    "        neighbors = np.argsort(distances.ravel())\n",
    "        nearest_centroid = neighbors[0]\n",
    "#         print(nearest_centroid)\n",
    "        ids[q] = c_ids[nearest_centroid]\n",
    "        if recompute_centroid:\n",
    "            # Recalculate centroids\n",
    "            c_ids, c_centroids = calculate_centroids(data, ids)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T00:51:04.255948Z",
     "start_time": "2018-11-30T00:51:04.252217Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score, silhouette_score, calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T06:07:35.214585Z",
     "start_time": "2018-11-30T06:07:35.149623Z"
    }
   },
   "outputs": [],
   "source": [
    "eps_range = np.linspace(0.00318, 0.00320, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T06:07:35.725682Z",
     "start_time": "2018-11-30T06:07:35.706873Z"
    }
   },
   "outputs": [],
   "source": [
    "X_dense = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T07:39:07.773270Z",
     "start_time": "2018-11-30T06:07:36.213765Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For eps: 0.00318, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5084.452\n",
      "For eps: 0.00318, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.00318, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.00318, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.00318, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.00318, minPts: 70\n",
      "  Estimated number of clusters: 4\n",
      "  Calinski Harabaz Score: 2836.041\n",
      "For eps: 0.0031810526315789473, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.0031810526315789473, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031810526315789473, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031810526315789473, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031810526315789473, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031810526315789473, minPts: 70\n",
      "  Estimated number of clusters: 4\n",
      "  Calinski Harabaz Score: 2836.041\n",
      "For eps: 0.003182105263157895, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.003182105263157895, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003182105263157895, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003182105263157895, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003182105263157895, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003182105263157895, minPts: 70\n",
      "  Estimated number of clusters: 4\n",
      "  Calinski Harabaz Score: 2836.041\n",
      "For eps: 0.003183157894736842, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.003183157894736842, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003183157894736842, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003183157894736842, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003183157894736842, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003183157894736842, minPts: 70\n",
      "  Estimated number of clusters: 4\n",
      "  Calinski Harabaz Score: 2836.041\n",
      "For eps: 0.0031842105263157894, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.0031842105263157894, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031842105263157894, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031842105263157894, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031842105263157894, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031842105263157894, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003185263157894737, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.003185263157894737, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003185263157894737, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003185263157894737, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003185263157894737, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003185263157894737, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031863157894736842, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.0031863157894736842, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031863157894736842, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031863157894736842, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031863157894736842, minPts: 69\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031863157894736842, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003187368421052632, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.003187368421052632, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003187368421052632, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003187368421052632, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003187368421052632, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003187368421052632, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003188421052631579, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.736\n",
      "For eps: 0.003188421052631579, minPts: 66\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003188421052631579, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003188421052631579, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003188421052631579, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003188421052631579, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031894736842105263, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5082.914\n",
      "For eps: 0.0031894736842105263, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.0031894736842105263, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031894736842105263, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031894736842105263, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.0031894736842105263, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003190526315789474, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.003190526315789474, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.003190526315789474, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003190526315789474, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003190526315789474, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003190526315789474, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003191578947368421, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.003191578947368421, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.003191578947368421, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003191578947368421, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003191578947368421, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003191578947368421, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031926315789473684, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.0031926315789473684, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.0031926315789473684, minPts: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031926315789473684, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031926315789473684, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.0031926315789473684, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003193684210526316, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.003193684210526316, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.003193684210526316, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003193684210526316, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003193684210526316, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003193684210526316, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031947368421052632, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.0031947368421052632, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.0031947368421052632, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031947368421052632, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.0031947368421052632, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.0031947368421052632, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003195789473684211, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.003195789473684211, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.003195789473684211, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003195789473684211, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003195789473684211, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003195789473684211, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003196842105263158, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.003196842105263158, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.003196842105263158, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003196842105263158, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5680.022\n",
      "For eps: 0.003196842105263158, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5683.867\n",
      "For eps: 0.003196842105263158, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0031978947368421053, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.0031978947368421053, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.0031978947368421053, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031978947368421053, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0031978947368421053, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5677.619\n",
      "For eps: 0.0031978947368421053, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.003198947368421053, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.003198947368421053, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5273.524\n",
      "For eps: 0.003198947368421053, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003198947368421053, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.003198947368421053, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5677.619\n",
      "For eps: 0.003198947368421053, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n",
      "For eps: 0.0032, minPts: 65\n",
      "  Estimated number of clusters: 8\n",
      "  Calinski Harabaz Score: 5083.048\n",
      "For eps: 0.0032, minPts: 66\n",
      "  Estimated number of clusters: 7\n",
      "  Calinski Harabaz Score: 5272.616\n",
      "For eps: 0.0032, minPts: 67\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0032, minPts: 68\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5675.218\n",
      "For eps: 0.0032, minPts: 69\n",
      "  Estimated number of clusters: 6\n",
      "  Calinski Harabaz Score: 5677.619\n",
      "For eps: 0.0032, minPts: 70\n",
      "  Estimated number of clusters: 5\n",
      "  Calinski Harabaz Score: 4334.672\n"
     ]
    }
   ],
   "source": [
    "optimal_ch_score = 0.0\n",
    "optimal_eps = 0.0\n",
    "optimal_pts = 0\n",
    "\n",
    "for epsilon in eps_range:\n",
    "    for min_pts in np.arange(21, 70, 3):\n",
    "        print(\"For eps: {}, minPts: {}\".format(epsilon, min_pts))\n",
    "        labels, core_pts, border_pts = DBSCAN(X, eps=epsilon, minPts=min_pts)\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        print('  Estimated number of clusters: %d' % n_clusters_)\n",
    "        if n_clusters_ in [0, 1]:\n",
    "            continue\n",
    "        labels = assign_noise_to_centroid(X, labels, recompute_centroid=True)\n",
    "\n",
    "        try:\n",
    "            score = calinski_harabaz_score(X_dense, labels)\n",
    "            print(\"  Calinski Harabaz Score: %0.3f\"\n",
    "              % score)\n",
    "            if score > optimal_ch_score:\n",
    "                optimal_ch_score = score\n",
    "                optimal_eps = epsilon\n",
    "                optimal_pts = min_pts\n",
    "                optimal_clusters = n_clusters_\n",
    "        except:\n",
    "            print(\"  Calinski Harabaz cannot be found on 1 cluster...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T07:39:07.780937Z",
     "start_time": "2018-11-30T07:39:07.775587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "For n_clusters: 6, eps: 0.003187368421052632, minPts: 69, optimal Calinski Harabaz Score is: 5683.867086583828\n"
     ]
    }
   ],
   "source": [
    "print(\"========================================================================\")           \n",
    "print(\"For n_clusters: {}, eps: {}, minPts: {}, optimal Calinski Harabaz Score is: {}\".format(\n",
    "    optimal_clusters, optimal_eps, optimal_pts, optimal_ch_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T03:34:37.089217Z",
     "start_time": "2018-11-23T01:54:54.762061Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimal_sil_score = 0.0\n",
    "optimal_eps = 0.0\n",
    "optimal_pts = 0\n",
    "\n",
    "for epsilon in eps_range:\n",
    "    for min_pts in np.arange(21, 70, 3):\n",
    "        print(\"For eps: {}, minPts: {}\".format(epsilon, min_pts))\n",
    "        labels, core_pts, border_pts = DBSCAN(X, eps=epsilon, minPts=min_pts)\n",
    "        labels = assign_noise_to_centroid(X, labels, recompute_centroid=True)\n",
    "#         labels = assign_noise_KNN(X, labels, K = min_pts - 1)\n",
    "    \n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        print('  Estimated number of clusters: %d' % n_clusters_)\n",
    "        if n_clusters_ == 1:\n",
    "            continue\n",
    "        try:\n",
    "            score = silhouette_score(X, labels, metric='cosine', random_state=8)\n",
    "            print(\"  Silhouette Coefficient: %0.3f\"\n",
    "              % score)\n",
    "            if score > optimal_sil_score:\n",
    "                optimal_sil_score = score\n",
    "                optimal_eps = epsilon\n",
    "                optimal_pts = min_pts\n",
    "                optimal_clusters = n_clusters_\n",
    "        except:\n",
    "            print(\"  Silhouette Coefficient cannot be found on 1 cluster...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T03:34:37.115496Z",
     "start_time": "2018-11-23T03:34:37.097925Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"========================================================================\")           \n",
    "print(\"For n_clusters: {}, eps: {}, minPts: {}, optimal silhouette coefficient is: {}\".format(\n",
    "    optimal_clusters, optimal_eps, optimal_pts, optimal_sil_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
